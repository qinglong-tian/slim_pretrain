{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PU Classifier Playground (Rewritten)\n",
    "\n",
    "This notebook follows one fixed PU workflow on five datasets and compares `latest_v1` vs `latest_v2`.\n",
    "\n",
    "Protocol:\n",
    "1. For each dataset, pick an inlier class, and split inliers into labeled-positive vs unlabeled-positive by `LP_UP_RATIO`.\n",
    "2. Build unlabeled data by mixing unlabeled-positive with sampled outliers based on `UNLABELED_OUTLIER_FRACTION`.\n",
    "3. Fit each checkpoint on labeled-positive only, then score unlabeled rows and report metrics.\n",
    "4. Repeat PU construction `NUM_REPEATS=10` times and average metrics per dataset/model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import io\n",
    "import re\n",
    "import zipfile\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from urllib.request import urlopen\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from sklearn.datasets import fetch_openml, load_breast_cancer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = Path.cwd().resolve()\n",
    "while repo_root != repo_root.parent and not (repo_root / 'simplified_prior').exists():\n",
    "    repo_root = repo_root.parent\n",
    "if not (repo_root / 'simplified_prior').exists():\n",
    "    raise RuntimeError('Could not find repo root containing simplified_prior/.')\n",
    "\n",
    "if str(repo_root.parent) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root.parent))\n",
    "\n",
    "from slim_pretrain.pretrain.model import NanoTabPFNPUClassifier\n",
    "\n",
    "print('Repo root:', repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model/runtime config\n",
    "CHECKPOINT_PATHS = {\n",
    "    'latest_v1': repo_root / 'checkpoints' / 'latest_v1.pt',\n",
    "    'latest_v2': repo_root / 'checkpoints' / 'latest_v2.pt',\n",
    "}\n",
    "DEVICE = 'auto'  # auto | cpu | cuda | mps\n",
    "\n",
    "# PU protocol config\n",
    "LP_UP_RATIO = (7, 3)  # 40% labeled-positive, 60% unlabeled-positive\n",
    "UNLABELED_OUTLIER_FRACTION = 0.7\n",
    "DEFAULT_INLIER_CLASS = 0\n",
    "INLIER_CLASS_BY_DATASET: Dict[str, int] = {\n",
    "    # Override per dataset if needed (values must be 0 or 1 after binary coercion).\n",
    "    'breast_cancer': 0,\n",
    "    'diabetes': 0,\n",
    "    'spambase_local': 0,\n",
    "    'banknote_authentication': 0,\n",
    "    'rice_cammeo_osmancik': 0,\n",
    "}\n",
    "\n",
    "NUM_REPEATS = 10\n",
    "BASE_SEED = 20260219\n",
    "THRESHOLD = 0.50\n",
    "USE_STANDARD_SCALER = False\n",
    "MAX_FEATURES: Optional[int] = None\n",
    "\n",
    "OPENML_CACHE_DIR = repo_root / '.cache' / 'openml'\n",
    "OPENML_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RICE_LOCAL_PATH = repo_root / 'notebooks' / 'benchmark' / 'rice+cammeo+and+osmancik.zip'\n",
    "SPAMBASE_LOCAL_PATH = repo_root / 'notebooks' / 'benchmark' / 'spambase.zip'\n",
    "BANKNOTE_LOCAL_PATH = repo_root / 'notebooks' / 'benchmark' / 'data_banknote_authentication.txt'\n",
    "\n",
    "# Five datasets used in this notebook.\n",
    "DATASET_SPECS = [\n",
    "    {\n",
    "        'source': 'sklearn',\n",
    "        'name': 'breast_cancer',\n",
    "    },\n",
    "    {\n",
    "        'source': 'openml',\n",
    "        'name': 'diabetes',\n",
    "        'version': 1,\n",
    "    },\n",
    "    {\n",
    "        'source': 'uci_url',\n",
    "        'name': 'spambase_local',\n",
    "        'url': str(SPAMBASE_LOCAL_PATH),\n",
    "        'url_fallbacks': [],\n",
    "        'archive_member_hint': 'spambase.data',\n",
    "        'sep': ',',\n",
    "        'header': None,\n",
    "        'target_col': 57,\n",
    "        'drop_cols': [],\n",
    "    },\n",
    "    {\n",
    "        'source': 'uci_url',\n",
    "        'name': 'banknote_authentication',\n",
    "        'url': str(BANKNOTE_LOCAL_PATH),\n",
    "        'url_fallbacks': [\n",
    "            'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt',\n",
    "        ],\n",
    "        'archive_member_hint': None,\n",
    "        'sep': ',',\n",
    "        'header': None,\n",
    "        'target_col': 4,\n",
    "        'drop_cols': [],\n",
    "    },\n",
    "    {\n",
    "        'source': 'uci_url',\n",
    "        'name': 'rice_cammeo_osmancik',\n",
    "        'url': str(RICE_LOCAL_PATH),\n",
    "        'url_fallbacks': [],\n",
    "        'archive_member_hint': 'Rice_Cammeo_Osmancik',\n",
    "        'sep': ',',\n",
    "        'header': 0,\n",
    "        'target_col': 'Class',\n",
    "        'drop_cols': [],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37da72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_device(device_arg: str) -> str:\n",
    "    if device_arg == 'auto':\n",
    "        if torch.cuda.is_available():\n",
    "            return 'cuda'\n",
    "        if getattr(torch.backends, 'mps', None) is not None and torch.backends.mps.is_available():\n",
    "            return 'mps'\n",
    "        return 'cpu'\n",
    "\n",
    "    if device_arg == 'cuda' and not torch.cuda.is_available():\n",
    "        raise RuntimeError('CUDA requested but not available.')\n",
    "\n",
    "    if device_arg == 'mps':\n",
    "        if getattr(torch.backends, 'mps', None) is None or not torch.backends.mps.is_available():\n",
    "            raise RuntimeError('MPS requested but not available.')\n",
    "\n",
    "    return device_arg\n",
    "\n",
    "\n",
    "def ratio_to_labeled_fraction(lp_up_ratio: Tuple[int, int]) -> float:\n",
    "    lp, up = int(lp_up_ratio[0]), int(lp_up_ratio[1])\n",
    "    if lp <= 0 or up <= 0:\n",
    "        raise ValueError(f'LP_UP_RATIO must be positive integers, got {lp_up_ratio}.')\n",
    "    return float(lp / (lp + up))\n",
    "\n",
    "\n",
    "def _decode_bytes_in_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if out[c].dtype == object:\n",
    "            out[c] = out[c].map(lambda v: v.decode('utf-8') if isinstance(v, (bytes, bytearray)) else v)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _read_arff_bytes(raw_bytes: bytes) -> pd.DataFrame:\n",
    "    try:\n",
    "        from scipy.io import arff as scipy_arff\n",
    "\n",
    "        records, _ = scipy_arff.loadarff(io.BytesIO(raw_bytes))\n",
    "        return _decode_bytes_in_df(pd.DataFrame(records))\n",
    "    except Exception:\n",
    "        text = raw_bytes.decode('utf-8', errors='replace')\n",
    "        attr_names: List[str] = []\n",
    "        data_lines: List[str] = []\n",
    "        in_data = False\n",
    "\n",
    "        for raw_line in text.splitlines():\n",
    "            line = raw_line.strip()\n",
    "            if not line or line.startswith('%'):\n",
    "                continue\n",
    "            low = line.lower()\n",
    "            if low.startswith('@data'):\n",
    "                in_data = True\n",
    "                continue\n",
    "            if not in_data:\n",
    "                if low.startswith('@attribute'):\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 2:\n",
    "                        attr_names.append(parts[1].strip(\"'\\\"\"))\n",
    "                continue\n",
    "            data_lines.append(raw_line)\n",
    "\n",
    "        if not attr_names or not data_lines:\n",
    "            raise RuntimeError('Could not parse ARFF content.')\n",
    "\n",
    "        csv_text = '\\n'.join(data_lines)\n",
    "        df = pd.read_csv(io.StringIO(csv_text), header=None)\n",
    "        if df.shape[1] != len(attr_names):\n",
    "            raise RuntimeError(\n",
    "                f'ARFF parser column mismatch: data cols={df.shape[1]} attributes={len(attr_names)}'\n",
    "            )\n",
    "        df.columns = attr_names\n",
    "        return _decode_bytes_in_df(df)\n",
    "\n",
    "\n",
    "def _read_bytes_from_source(source: str) -> bytes:\n",
    "    source_l = source.lower()\n",
    "    if source_l.startswith('http://') or source_l.startswith('https://'):\n",
    "        with urlopen(source, timeout=60) as resp:\n",
    "            return resp.read()\n",
    "    return Path(source).expanduser().read_bytes()\n",
    "\n",
    "\n",
    "def _load_uci_table_with_fallbacks(\n",
    "    url_candidates: List[str],\n",
    "    sep: str,\n",
    "    header: Optional[int],\n",
    "    archive_member_hint: Optional[str],\n",
    ") -> pd.DataFrame:\n",
    "    last_exc = None\n",
    "\n",
    "    for u in url_candidates:\n",
    "        try:\n",
    "            u_l = u.lower()\n",
    "\n",
    "            if u_l.endswith('.zip'):\n",
    "                archive_bytes = _read_bytes_from_source(u)\n",
    "                with zipfile.ZipFile(io.BytesIO(archive_bytes)) as zf:\n",
    "                    members = [m for m in zf.namelist() if not m.endswith('/')]\n",
    "                    if not members:\n",
    "                        raise RuntimeError(f'No files found in archive: {u}')\n",
    "\n",
    "                    preferred = members\n",
    "                    if archive_member_hint:\n",
    "                        hinted = [m for m in members if archive_member_hint.lower() in m.lower()]\n",
    "                        if hinted:\n",
    "                            preferred = hinted\n",
    "\n",
    "                    selected = None\n",
    "                    for ext in ('.csv', '.data', '.txt', '.arff'):\n",
    "                        for m in preferred:\n",
    "                            if m.lower().endswith(ext):\n",
    "                                selected = m\n",
    "                                break\n",
    "                        if selected is not None:\n",
    "                            break\n",
    "                    if selected is None:\n",
    "                        selected = preferred[0]\n",
    "\n",
    "                    payload = zf.read(selected)\n",
    "                    if selected.lower().endswith('.arff'):\n",
    "                        return _read_arff_bytes(payload)\n",
    "\n",
    "                    return pd.read_csv(io.BytesIO(payload), sep=sep, header=header, skipinitialspace=True)\n",
    "\n",
    "            if u_l.endswith('.arff'):\n",
    "                return _read_arff_bytes(_read_bytes_from_source(u))\n",
    "\n",
    "            return pd.read_csv(u, sep=sep, header=header, skipinitialspace=True)\n",
    "\n",
    "        except Exception as exc:\n",
    "            last_exc = exc\n",
    "\n",
    "    raise RuntimeError(f'Failed loading UCI source(s): {url_candidates}. Last error: {last_exc}')\n",
    "\n",
    "\n",
    "def _coerce_binary_target(y_raw: pd.Series) -> Tuple[np.ndarray, Dict[str, int], np.ndarray]:\n",
    "    y_series = pd.Series(y_raw).copy()\n",
    "    y_series = y_series.replace(['?', 'nan', 'None'], np.nan)\n",
    "    valid = y_series.notna().to_numpy()\n",
    "    y_series = y_series[valid]\n",
    "\n",
    "    labels = sorted(list(pd.unique(y_series)), key=lambda x: str(x))\n",
    "    if len(labels) != 2:\n",
    "        raise ValueError(f'Expected binary labels, got {len(labels)} labels: {labels[:10]}')\n",
    "\n",
    "    mapping = {labels[0]: 0, labels[1]: 1}\n",
    "    y = y_series.map(mapping).astype(np.int64).to_numpy()\n",
    "    mapping_printable = {str(k): int(v) for k, v in mapping.items()}\n",
    "    return y, mapping_printable, valid\n",
    "\n",
    "\n",
    "def _coerce_numeric_features(X_raw: pd.DataFrame) -> np.ndarray:\n",
    "    X_df = pd.DataFrame(X_raw).copy()\n",
    "\n",
    "    for c in X_df.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(X_df[c]):\n",
    "            X_df[c] = X_df[c].astype(str)\n",
    "\n",
    "    X_df = pd.get_dummies(X_df, dummy_na=True, drop_first=False)\n",
    "    X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    numeric_medians = X_df.median(numeric_only=True)\n",
    "    X_df = X_df.fillna(numeric_medians)\n",
    "    X_df = X_df.fillna(0.0)\n",
    "    return X_df.to_numpy(dtype=np.float32)\n",
    "\n",
    "\n",
    "def load_dataset_from_spec(spec: Dict[str, object]) -> Dict[str, object]:\n",
    "    source = str(spec['source'])\n",
    "    name = str(spec['name'])\n",
    "\n",
    "    if source == 'sklearn' and name == 'breast_cancer':\n",
    "        ds = load_breast_cancer(as_frame=True)\n",
    "        X_raw = ds.data\n",
    "        y_raw = ds.target\n",
    "\n",
    "    elif source == 'openml':\n",
    "        version = int(spec.get('version', 1))\n",
    "        ds = fetch_openml(name=name, version=version, as_frame=True, data_home=str(OPENML_CACHE_DIR))\n",
    "        X_raw = ds.data\n",
    "        y_raw = ds.target\n",
    "\n",
    "    elif source == 'uci_url':\n",
    "        sep = spec.get('sep', ',')\n",
    "        header = spec.get('header', None)\n",
    "        target_col = spec['target_col']\n",
    "        drop_cols = set(spec.get('drop_cols', []))\n",
    "        archive_member_hint = spec.get('archive_member_hint')\n",
    "\n",
    "        url_candidates = [str(spec['url'])] + [str(u) for u in spec.get('url_fallbacks', [])]\n",
    "        raw = _load_uci_table_with_fallbacks(\n",
    "            url_candidates=url_candidates,\n",
    "            sep=sep,\n",
    "            header=header,\n",
    "            archive_member_hint=str(archive_member_hint) if archive_member_hint is not None else None,\n",
    "        )\n",
    "\n",
    "        if isinstance(target_col, str):\n",
    "            if target_col not in raw.columns:\n",
    "                raise ValueError(f\"target_col='{target_col}' not found in columns: {list(raw.columns)[:20]}\")\n",
    "            target_key = target_col\n",
    "        else:\n",
    "            target_key = raw.columns[int(target_col)]\n",
    "\n",
    "        y_raw = raw[target_key]\n",
    "        feature_cols = [c for c in raw.columns if c != target_key and c not in drop_cols]\n",
    "        X_raw = raw.loc[:, feature_cols]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported dataset spec: {spec}')\n",
    "\n",
    "    X = _coerce_numeric_features(pd.DataFrame(X_raw))\n",
    "    y, label_mapping, valid_mask = _coerce_binary_target(pd.Series(y_raw))\n",
    "\n",
    "    if X.shape[0] != len(y):\n",
    "        X = X[valid_mask]\n",
    "\n",
    "    if MAX_FEATURES is not None and MAX_FEATURES > 0 and X.shape[1] > MAX_FEATURES:\n",
    "        X = X[:, :MAX_FEATURES]\n",
    "\n",
    "    inverse_mapping = {int(v): k for k, v in label_mapping.items()}\n",
    "\n",
    "    return {\n",
    "        'source': source,\n",
    "        'name': name,\n",
    "        'X': X.astype(np.float32),\n",
    "        'y': y.astype(np.int64),\n",
    "        'n_rows': int(X.shape[0]),\n",
    "        'n_features': int(X.shape[1]),\n",
    "        'label_mapping': label_mapping,\n",
    "        'inverse_label_mapping': inverse_mapping,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add113b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pu_data(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    inlier_class: int,\n",
    "    labeled_positive_fraction: float,\n",
    "    unlabeled_outlier_fraction: float,\n",
    "    seed: int,\n",
    ") -> Dict[str, object]:\n",
    "    if inlier_class not in {0, 1}:\n",
    "        raise ValueError(f'inlier_class must be 0/1, got {inlier_class}')\n",
    "    if not (0.0 < labeled_positive_fraction < 1.0):\n",
    "        raise ValueError(f'labeled_positive_fraction must be in (0, 1), got {labeled_positive_fraction}')\n",
    "    if not (0.0 <= unlabeled_outlier_fraction < 1.0):\n",
    "        raise ValueError(f'unlabeled_outlier_fraction must be in [0, 1), got {unlabeled_outlier_fraction}')\n",
    "\n",
    "    inlier_idx = np.where(y == inlier_class)[0]\n",
    "    outlier_idx = np.where(y != inlier_class)[0]\n",
    "\n",
    "    n_inlier = len(inlier_idx)\n",
    "    n_outlier_pool = len(outlier_idx)\n",
    "    if n_inlier < 2:\n",
    "        raise RuntimeError('Need at least 2 inliers to split labeled/unlabeled positives.')\n",
    "\n",
    "    n_labeled_pos = int(round(n_inlier * labeled_positive_fraction))\n",
    "    n_labeled_pos = max(1, min(n_labeled_pos, n_inlier - 1))\n",
    "    n_unlabeled_pos = n_inlier - n_labeled_pos\n",
    "\n",
    "    desired_n_unlabeled_out = int(round(\n",
    "        (unlabeled_outlier_fraction / max(1e-12, 1.0 - unlabeled_outlier_fraction)) * n_unlabeled_pos\n",
    "    ))\n",
    "    if unlabeled_outlier_fraction > 0.0 and desired_n_unlabeled_out == 0:\n",
    "        desired_n_unlabeled_out = 1\n",
    "\n",
    "    n_unlabeled_out = min(desired_n_unlabeled_out, n_outlier_pool)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    inlier_perm = rng.permutation(inlier_idx)\n",
    "    outlier_perm = rng.permutation(outlier_idx)\n",
    "\n",
    "    labeled_idx = inlier_perm[:n_labeled_pos]\n",
    "    unlabeled_pos_idx = inlier_perm[n_labeled_pos:]\n",
    "    unlabeled_out_idx = outlier_perm[:n_unlabeled_out]\n",
    "\n",
    "    unlabeled_idx = np.concatenate([unlabeled_pos_idx, unlabeled_out_idx], axis=0)\n",
    "    y_unlabeled_true = np.concatenate([\n",
    "        np.zeros(len(unlabeled_pos_idx), dtype=np.int64),\n",
    "        np.ones(len(unlabeled_out_idx), dtype=np.int64),\n",
    "    ])\n",
    "\n",
    "    perm_u = rng.permutation(len(unlabeled_idx))\n",
    "    unlabeled_idx = unlabeled_idx[perm_u]\n",
    "    y_unlabeled_true = y_unlabeled_true[perm_u]\n",
    "\n",
    "    X_labeled_pos = X[labeled_idx]\n",
    "    X_unlabeled = X[unlabeled_idx]\n",
    "\n",
    "    actual_unlabeled_outlier_fraction = float(y_unlabeled_true.mean()) if len(y_unlabeled_true) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        'X_labeled_pos': X_labeled_pos,\n",
    "        'X_unlabeled': X_unlabeled,\n",
    "        'y_unlabeled_true': y_unlabeled_true,\n",
    "        'n_total': int(len(y)),\n",
    "        'n_inlier_total': int(n_inlier),\n",
    "        'n_outlier_pool': int(n_outlier_pool),\n",
    "        'n_labeled_pos': int(n_labeled_pos),\n",
    "        'n_unlabeled_pos': int(len(unlabeled_pos_idx)),\n",
    "        'n_unlabeled_out': int(len(unlabeled_out_idx)),\n",
    "        'n_unlabeled_total': int(len(unlabeled_idx)),\n",
    "        'requested_unlabeled_outlier_fraction': float(unlabeled_outlier_fraction),\n",
    "        'actual_unlabeled_outlier_fraction': float(actual_unlabeled_outlier_fraction),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_on_pu(\n",
    "    clf: NanoTabPFNPUClassifier,\n",
    "    X_labeled_pos: np.ndarray,\n",
    "    X_unlabeled: np.ndarray,\n",
    "    y_unlabeled_true: np.ndarray,\n",
    "    threshold: float,\n",
    "    use_standard_scaler: bool,\n",
    ") -> Dict[str, float]:\n",
    "    X_train = X_labeled_pos\n",
    "    X_test = X_unlabeled\n",
    "\n",
    "    if use_standard_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(np.concatenate([X_train, X_test], axis=0))\n",
    "        X_train = scaler.transform(X_train).astype(np.float32)\n",
    "        X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "    clf.fit(X_train)\n",
    "    outlier_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (outlier_proba >= threshold).astype(np.int64)\n",
    "\n",
    "    cm = confusion_matrix(y_unlabeled_true, y_pred, labels=[0, 1])\n",
    "\n",
    "    if len(np.unique(y_unlabeled_true)) == 2:\n",
    "        roc_auc = float(roc_auc_score(y_unlabeled_true, outlier_proba))\n",
    "        average_precision = float(average_precision_score(y_unlabeled_true, outlier_proba))\n",
    "    else:\n",
    "        roc_auc = np.nan\n",
    "        average_precision = np.nan\n",
    "\n",
    "    return {\n",
    "        'accuracy': float(accuracy_score(y_unlabeled_true, y_pred)),\n",
    "        'balanced_accuracy': float(balanced_accuracy_score(y_unlabeled_true, y_pred)),\n",
    "        'precision': float(precision_score(y_unlabeled_true, y_pred, zero_division=0)),\n",
    "        'recall': float(recall_score(y_unlabeled_true, y_pred, zero_division=0)),\n",
    "        'f1': float(f1_score(y_unlabeled_true, y_pred, zero_division=0)),\n",
    "        'roc_auc': roc_auc,\n",
    "        'average_precision': average_precision,\n",
    "        'cm_00': int(cm[0, 0]),\n",
    "        'cm_01': int(cm[0, 1]),\n",
    "        'cm_10': int(cm[1, 0]),\n",
    "        'cm_11': int(cm[1, 1]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = resolve_device(DEVICE)\n",
    "labeled_positive_fraction = ratio_to_labeled_fraction(LP_UP_RATIO)\n",
    "\n",
    "missing_ckpts = [name for name, path in CHECKPOINT_PATHS.items() if not path.exists()]\n",
    "if missing_ckpts:\n",
    "    raise RuntimeError(f'Missing checkpoints: {missing_ckpts}. Expected: {CHECKPOINT_PATHS}')\n",
    "\n",
    "models: Dict[str, NanoTabPFNPUClassifier] = {}\n",
    "for model_name, ckpt_path in CHECKPOINT_PATHS.items():\n",
    "    models[model_name] = NanoTabPFNPUClassifier.from_checkpoint(ckpt_path, device=device)\n",
    "\n",
    "print('Device:', device)\n",
    "print('Models:', {k: str(v) for k, v in CHECKPOINT_PATHS.items()})\n",
    "print('LP_UP_RATIO:', LP_UP_RATIO, f'-> labeled_positive_fraction={labeled_positive_fraction:.4f}')\n",
    "print('UNLABELED_OUTLIER_FRACTION:', UNLABELED_OUTLIER_FRACTION)\n",
    "print('NUM_REPEATS:', NUM_REPEATS)\n",
    "\n",
    "loaded_datasets: List[Dict[str, object]] = []\n",
    "failed_datasets: List[Dict[str, object]] = []\n",
    "\n",
    "for spec in DATASET_SPECS:\n",
    "    try:\n",
    "        ds = load_dataset_from_spec(spec)\n",
    "        loaded_datasets.append(ds)\n",
    "        print(\n",
    "            f\"[OK] {ds['source']}::{ds['name']} rows={ds['n_rows']} features={ds['n_features']} labels={ds['label_mapping']}\"\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        failed_datasets.append({'spec': spec, 'error': str(exc)})\n",
    "        print(f\"[FAIL] {spec['source']}::{spec['name']} -> {exc}\")\n",
    "\n",
    "if len(loaded_datasets) != 5:\n",
    "    raise RuntimeError(\n",
    "        f'Expected 5 datasets loaded, got {len(loaded_datasets)}. Failed: {failed_datasets}'\n",
    "    )\n",
    "\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                'source': ds['source'],\n",
    "                'dataset': ds['name'],\n",
    "                'rows': ds['n_rows'],\n",
    "                'features': ds['n_features'],\n",
    "                'label_mapping': str(ds['label_mapping']),\n",
    "                'default_inlier_class': INLIER_CLASS_BY_DATASET.get(ds['name'], DEFAULT_INLIER_CLASS),\n",
    "                'default_inlier_raw_label': str(\n",
    "                    ds['inverse_label_mapping'].get(\n",
    "                        INLIER_CLASS_BY_DATASET.get(ds['name'], DEFAULT_INLIER_CLASS),\n",
    "                        'unknown',\n",
    "                    )\n",
    "                ),\n",
    "            }\n",
    "            for ds in loaded_datasets\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a51c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_rows: List[Dict[str, object]] = []\n",
    "\n",
    "for repeat_idx in range(NUM_REPEATS):\n",
    "    print(f'Running repeat {repeat_idx + 1}/{NUM_REPEATS} ...')\n",
    "    for dataset_idx, ds in enumerate(loaded_datasets):\n",
    "        ds_name = str(ds['name'])\n",
    "        inlier_class = int(INLIER_CLASS_BY_DATASET.get(ds_name, DEFAULT_INLIER_CLASS))\n",
    "        split_seed = BASE_SEED + repeat_idx * 1000 + dataset_idx\n",
    "\n",
    "        pu = build_pu_data(\n",
    "            X=ds['X'],\n",
    "            y=ds['y'],\n",
    "            inlier_class=inlier_class,\n",
    "            labeled_positive_fraction=labeled_positive_fraction,\n",
    "            unlabeled_outlier_fraction=UNLABELED_OUTLIER_FRACTION,\n",
    "            seed=split_seed,\n",
    "        )\n",
    "\n",
    "        for model_name, clf in models.items():\n",
    "            metrics = evaluate_on_pu(\n",
    "                clf=clf,\n",
    "                X_labeled_pos=pu['X_labeled_pos'],\n",
    "                X_unlabeled=pu['X_unlabeled'],\n",
    "                y_unlabeled_true=pu['y_unlabeled_true'],\n",
    "                threshold=THRESHOLD,\n",
    "                use_standard_scaler=USE_STANDARD_SCALER,\n",
    "            )\n",
    "\n",
    "            repeat_rows.append(\n",
    "                {\n",
    "                    'repeat': int(repeat_idx),\n",
    "                    'split_seed': int(split_seed),\n",
    "                    'dataset': ds_name,\n",
    "                    'source': ds['source'],\n",
    "                    'model': model_name,\n",
    "                    'inlier_class': int(inlier_class),\n",
    "                    'inlier_raw_label': str(ds['inverse_label_mapping'].get(inlier_class, 'unknown')),\n",
    "                    'outlier_raw_label': str(ds['inverse_label_mapping'].get(1 - inlier_class, 'unknown')),\n",
    "                    'n_rows': int(ds['n_rows']),\n",
    "                    'n_features': int(ds['n_features']),\n",
    "                    'n_labeled_pos': int(pu['n_labeled_pos']),\n",
    "                    'n_unlabeled_pos': int(pu['n_unlabeled_pos']),\n",
    "                    'n_unlabeled_out': int(pu['n_unlabeled_out']),\n",
    "                    'n_unlabeled_total': int(pu['n_unlabeled_total']),\n",
    "                    'requested_unlabeled_outlier_fraction': float(pu['requested_unlabeled_outlier_fraction']),\n",
    "                    'actual_unlabeled_outlier_fraction': float(pu['actual_unlabeled_outlier_fraction']),\n",
    "                    **metrics,\n",
    "                }\n",
    "            )\n",
    "\n",
    "repeat_results_df = pd.DataFrame(repeat_rows)\n",
    "if repeat_results_df.empty:\n",
    "    raise RuntimeError('No repeat results were produced.')\n",
    "\n",
    "print('\\nPer-repeat snapshot (first 20 rows): identifiers + composition')\n",
    "repeat_view_cols = [\n",
    "    'repeat', 'dataset', 'model', 'inlier_raw_label', 'outlier_raw_label',\n",
    "    'n_labeled_pos', 'n_unlabeled_pos', 'n_unlabeled_out', 'n_unlabeled_total',\n",
    "    'actual_unlabeled_outlier_fraction',\n",
    "]\n",
    "display(repeat_results_df[repeat_view_cols].head(20))\n",
    "\n",
    "print('Per-repeat snapshot (first 20 rows): metrics')\n",
    "repeat_metric_cols = [\n",
    "    'repeat', 'dataset', 'model',\n",
    "    'accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision',\n",
    "]\n",
    "display(repeat_results_df[repeat_metric_cols].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = [\n",
    "    'accuracy',\n",
    "    'balanced_accuracy',\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1',\n",
    "    'roc_auc',\n",
    "    'average_precision',\n",
    "]\n",
    "\n",
    "composition_cols = [\n",
    "    'n_labeled_pos',\n",
    "    'n_unlabeled_pos',\n",
    "    'n_unlabeled_out',\n",
    "    'n_unlabeled_total',\n",
    "    'requested_unlabeled_outlier_fraction',\n",
    "    'actual_unlabeled_outlier_fraction',\n",
    "]\n",
    "\n",
    "avg_metrics_df = (\n",
    "    repeat_results_df\n",
    "    .groupby(['dataset', 'model'], as_index=False)[metric_cols + composition_cols]\n",
    "    .mean()\n",
    "    .sort_values(['dataset', 'model'])\n",
    ")\n",
    "\n",
    "std_metrics_df = (\n",
    "    repeat_results_df\n",
    "    .groupby(['dataset', 'model'], as_index=False)[metric_cols]\n",
    "    .std()\n",
    "    .rename(columns={c: f'{c}_std' for c in metric_cols})\n",
    ")\n",
    "\n",
    "summary_df = avg_metrics_df.merge(std_metrics_df, on=['dataset', 'model'], how='left')\n",
    "\n",
    "print('Average over repeats: compact metric view')\n",
    "summary_metric_view_cols = [\n",
    "    'dataset', 'model',\n",
    "    'roc_auc', 'average_precision', 'f1', 'balanced_accuracy', 'accuracy', 'precision', 'recall',\n",
    "]\n",
    "display(summary_df[summary_metric_view_cols].sort_values(['dataset', 'model']))\n",
    "\n",
    "print('Average over repeats: PU composition view')\n",
    "summary_composition_view_cols = [\n",
    "    'dataset', 'model',\n",
    "    'n_labeled_pos', 'n_unlabeled_pos', 'n_unlabeled_out', 'n_unlabeled_total',\n",
    "    'requested_unlabeled_outlier_fraction', 'actual_unlabeled_outlier_fraction',\n",
    "]\n",
    "display(summary_df[summary_composition_view_cols].sort_values(['dataset', 'model']))\n",
    "\n",
    "print('Average over repeats: metric mean/std view')\n",
    "summary_metric_std_cols = ['dataset', 'model']\n",
    "for c in metric_cols:\n",
    "    summary_metric_std_cols.extend([c, f'{c}_std'])\n",
    "display(summary_df[summary_metric_std_cols].sort_values(['dataset', 'model']))\n",
    "\n",
    "roc_auc_pivot = summary_df.pivot_table(index='dataset', columns='model', values='roc_auc')\n",
    "print('Mean ROC-AUC by dataset/model:')\n",
    "display(roc_auc_pivot)\n",
    "\n",
    "avg_by_model = summary_df.groupby('model', as_index=False)[metric_cols].mean().sort_values('roc_auc', ascending=False)\n",
    "print('Dataset-averaged metrics by model:')\n",
    "display(avg_by_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e10d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: inspect one dataset/model in detail\n",
    "example_dataset = summary_df['dataset'].iloc[0]\n",
    "example_model = summary_df['model'].iloc[0]\n",
    "\n",
    "print(f'Detailed per-repeat rows for dataset={example_dataset}, model={example_model}: composition')\n",
    "detailed_df = repeat_results_df[\n",
    "    (repeat_results_df['dataset'] == example_dataset)\n",
    "    & (repeat_results_df['model'] == example_model)\n",
    "].sort_values('repeat')\n",
    "display(detailed_df[[\n",
    "    'repeat', 'split_seed', 'n_labeled_pos', 'n_unlabeled_pos', 'n_unlabeled_out',\n",
    "    'n_unlabeled_total', 'actual_unlabeled_outlier_fraction',\n",
    "]])\n",
    "\n",
    "print('Detailed per-repeat rows: metrics')\n",
    "display(detailed_df[[\n",
    "    'repeat', 'accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision',\n",
    "]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
