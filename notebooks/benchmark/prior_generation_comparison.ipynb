{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Generation Comparison (`head` vs `roots` vs `is_causal=True`)\n",
    "\n",
    "This notebook benchmarks classification difficulty across three prior data-generation modes:\n",
    "\n",
    "- `is_causal=False`, `noncausal_feature_source=\"head\"`\n",
    "- `is_causal=False`, `noncausal_feature_source=\"roots\"` (TabICL-like roots as features)\n",
    "- `is_causal=True` (intermediate-node feature sampling)\n",
    "\n",
    "Constraints in this benchmark:\n",
    "\n",
    "- No PU row dropping and no hidden labels (`pu_keep_probability=1.0`)\n",
    "- Train and test splits both contain two classes for every sampled dataset\n",
    "- Other prior settings stay aligned with `default_base_prior_config()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/qltian/Library/CloudStorage/GoogleDrive-qltian2021@gmail.com/Other computers/My Laptop/Documents/Research/ai/slim_pretrain\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "repo_root = Path.cwd().resolve()\n",
    "while repo_root != repo_root.parent and not (repo_root / \"simplified_prior\").exists():\n",
    "    repo_root = repo_root.parent\n",
    "if not (repo_root / \"simplified_prior\").exists():\n",
    "    raise RuntimeError(\"Could not find repo root containing simplified_prior/.\")\n",
    "\n",
    "if str(repo_root.parent) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root.parent))\n",
    "\n",
    "print(\"Repo root:\", repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost available: True\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import replace\n",
    "import warnings\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from slim_pretrain.pretrain.train import default_base_prior_config\n",
    "from slim_pretrain.simplified_prior import SimplifiedPriorConfig, generate_simplified_prior_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"sklearn\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAVE_XGBOOST = True\n",
    "except Exception:\n",
    "    HAVE_XGBOOST = False\n",
    "\n",
    "print(\"xgboost available:\", HAVE_XGBOOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets per mode: 30\n"
     ]
    }
   ],
   "source": [
    "# Benchmark size: increase for a more stable comparison.\n",
    "N_DATASETS_PER_MODE = 30\n",
    "MAX_TRIES_PER_DATASET = 300\n",
    "BASE_SEED = 123\n",
    "\n",
    "MODES = [\"noncausal_head\", \"noncausal_roots\", \"causal_intermediate\"]\n",
    "MODE_LABELS = {\n",
    "    \"noncausal_head\": \"is_causal=False + head\",\n",
    "    \"noncausal_roots\": \"is_causal=False + roots\",\n",
    "    \"causal_intermediate\": \"is_causal=True\",\n",
    "}\n",
    "\n",
    "print(\"Datasets per mode:\", N_DATASETS_PER_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mode_config(base_cfg: SimplifiedPriorConfig, mode: str) -> SimplifiedPriorConfig:\n",
    "    common = dict(\n",
    "        pu_keep_probability=1.0,  # keep full labels; no PU hidden rows\n",
    "    )\n",
    "    if mode == \"noncausal_head\":\n",
    "        return replace(base_cfg, is_causal=False, noncausal_feature_source=\"head\", **common)\n",
    "    if mode == \"noncausal_roots\":\n",
    "        # TabICL-like non-causal mode: roots as observed features.\n",
    "        return replace(\n",
    "            base_cfg,\n",
    "            is_causal=False,\n",
    "            noncausal_feature_source=\"roots\",\n",
    "            num_causes=base_cfg.num_features,\n",
    "            **common,\n",
    "        )\n",
    "    if mode == \"causal_intermediate\":\n",
    "        return replace(base_cfg, is_causal=True, **common)\n",
    "    raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "\n",
    "def generate_valid_dataset(cfg: SimplifiedPriorConfig, seed_start: int, max_tries: int = 200) -> Dict[str, np.ndarray]:\n",
    "    for offset in range(max_tries):\n",
    "        cfg_try = replace(cfg, seed=seed_start + offset)\n",
    "        out = generate_simplified_prior_data(cfg_try, num_datasets=1)\n",
    "\n",
    "        X = out[\"X\"][0].cpu().numpy()\n",
    "        y = out[\"y\"][0].cpu().numpy()\n",
    "        train_size = int(out[\"train_sizes\"][0].item())\n",
    "        is_pu = bool(out[\"is_pu\"][0].item())\n",
    "\n",
    "        # Requirement 1: keep original full labels (no PU hiding).\n",
    "        if is_pu:\n",
    "            continue\n",
    "        if np.any(y < 0):\n",
    "            continue\n",
    "\n",
    "        X_train = X[:train_size]\n",
    "        y_train = y[:train_size]\n",
    "        X_test = X[train_size:]\n",
    "        y_test = y[train_size:]\n",
    "\n",
    "        # Requirement 1: both train/test contain two classes.\n",
    "        if len(np.unique(y_train)) != 2:\n",
    "            continue\n",
    "        if len(np.unique(y_test)) != 2:\n",
    "            continue\n",
    "\n",
    "        return {\n",
    "            \"X_train\": X_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_test\": y_test,\n",
    "            \"seed\": seed_start + offset,\n",
    "        }\n",
    "\n",
    "    raise RuntimeError(\"Failed to sample a valid binary train/test split with full labels.\")\n",
    "\n",
    "\n",
    "def build_models(random_state: int):\n",
    "    models = {\n",
    "        \"logreg\": Pipeline(\n",
    "            [\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"clf\", LogisticRegression(max_iter=5000, random_state=random_state)),\n",
    "            ]\n",
    "        ),\n",
    "        \"svm_rbf\": Pipeline(\n",
    "            [\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"clf\", SVC(kernel=\"rbf\", C=1.0, probability=True, random_state=random_state)),\n",
    "            ]\n",
    "        ),\n",
    "        \"random_forest\": RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "        ),\n",
    "    }\n",
    "    if HAVE_XGBOOST:\n",
    "        models[\"xgboost\"] = XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=random_state,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "    return models\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        score = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        score = model.decision_function(X_test)\n",
    "    else:\n",
    "        score = pred\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_test, pred),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_test, pred),\n",
    "        \"f1\": f1_score(y_test, pred),\n",
    "        \"roc_auc\": roc_auc_score(y_test, score),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark rows: 360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_features</th>\n",
       "      <th>train_class0</th>\n",
       "      <th>train_class1</th>\n",
       "      <th>test_class0</th>\n",
       "      <th>test_class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_causal=False + head</td>\n",
       "      <td>123</td>\n",
       "      <td>179</td>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>96</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_causal=False + roots</td>\n",
       "      <td>1000123</td>\n",
       "      <td>179</td>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is_causal=True</td>\n",
       "      <td>2000123</td>\n",
       "      <td>179</td>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mode     seed  n_train  n_test  n_features  \\\n",
       "0   is_causal=False + head      123      179      77          20   \n",
       "1  is_causal=False + roots  1000123      179      77          20   \n",
       "2           is_causal=True  2000123      179      77          20   \n",
       "\n",
       "   train_class0  train_class1  test_class0  test_class1  \n",
       "0            83            96           45           32  \n",
       "1            91            88           37           40  \n",
       "2            89            90           39           38  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_cfg = default_base_prior_config()\n",
    "\n",
    "rows = []\n",
    "sample_dataset_summaries = []\n",
    "\n",
    "for mode_idx, mode in enumerate(MODES):\n",
    "    cfg = build_mode_config(base_cfg, mode)\n",
    "    for ds_idx in range(N_DATASETS_PER_MODE):\n",
    "        seed_start = BASE_SEED + mode_idx * 1_000_000 + ds_idx * 1_000\n",
    "        dataset = generate_valid_dataset(cfg, seed_start=seed_start, max_tries=MAX_TRIES_PER_DATASET)\n",
    "\n",
    "        X_train = dataset[\"X_train\"]\n",
    "        y_train = dataset[\"y_train\"]\n",
    "        X_test = dataset[\"X_test\"]\n",
    "        y_test = dataset[\"y_test\"]\n",
    "\n",
    "        if ds_idx == 0:\n",
    "            sample_dataset_summaries.append(\n",
    "                {\n",
    "                    \"mode\": MODE_LABELS[mode],\n",
    "                    \"seed\": dataset[\"seed\"],\n",
    "                    \"n_train\": len(y_train),\n",
    "                    \"n_test\": len(y_test),\n",
    "                    \"n_features\": X_train.shape[1],\n",
    "                    \"train_class0\": int((y_train == 0).sum()),\n",
    "                    \"train_class1\": int((y_train == 1).sum()),\n",
    "                    \"test_class0\": int((y_test == 0).sum()),\n",
    "                    \"test_class1\": int((y_test == 1).sum()),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        models = build_models(random_state=seed_start + 77)\n",
    "        for model_name, model in models.items():\n",
    "            try:\n",
    "                metrics = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"mode\": MODE_LABELS[mode],\n",
    "                        \"dataset_id\": ds_idx,\n",
    "                        \"model\": model_name,\n",
    "                        \"status\": \"ok\",\n",
    "                        \"error\": \"\",\n",
    "                        **metrics,\n",
    "                    }\n",
    "                )\n",
    "            except Exception as exc:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"mode\": MODE_LABELS[mode],\n",
    "                        \"dataset_id\": ds_idx,\n",
    "                        \"model\": model_name,\n",
    "                        \"status\": \"error\",\n",
    "                        \"error\": str(exc),\n",
    "                        \"accuracy\": np.nan,\n",
    "                        \"balanced_accuracy\": np.nan,\n",
    "                        \"f1\": np.nan,\n",
    "                        \"roc_auc\": np.nan,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "sample_summary_df = pd.DataFrame(sample_dataset_summaries)\n",
    "\n",
    "print(\"Benchmark rows:\", len(results_df))\n",
    "sample_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful model runs: 360 / 360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_causal=False + head</td>\n",
       "      <td>logreg</td>\n",
       "      <td>0.855411</td>\n",
       "      <td>0.857489</td>\n",
       "      <td>0.850273</td>\n",
       "      <td>0.940286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is_causal=False + head</td>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>0.800866</td>\n",
       "      <td>0.804322</td>\n",
       "      <td>0.796572</td>\n",
       "      <td>0.888548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is_causal=False + head</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.787013</td>\n",
       "      <td>0.788717</td>\n",
       "      <td>0.782355</td>\n",
       "      <td>0.870410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_causal=False + head</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.773593</td>\n",
       "      <td>0.776275</td>\n",
       "      <td>0.766658</td>\n",
       "      <td>0.860990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is_causal=False + roots</td>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>0.561472</td>\n",
       "      <td>0.567915</td>\n",
       "      <td>0.556512</td>\n",
       "      <td>0.576042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_causal=False + roots</td>\n",
       "      <td>logreg</td>\n",
       "      <td>0.561039</td>\n",
       "      <td>0.566182</td>\n",
       "      <td>0.555728</td>\n",
       "      <td>0.587825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is_causal=False + roots</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.548485</td>\n",
       "      <td>0.555309</td>\n",
       "      <td>0.544447</td>\n",
       "      <td>0.569962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is_causal=False + roots</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.529004</td>\n",
       "      <td>0.533560</td>\n",
       "      <td>0.531471</td>\n",
       "      <td>0.558644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is_causal=True</td>\n",
       "      <td>logreg</td>\n",
       "      <td>0.734199</td>\n",
       "      <td>0.737136</td>\n",
       "      <td>0.734590</td>\n",
       "      <td>0.809973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is_causal=True</td>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>0.720346</td>\n",
       "      <td>0.723962</td>\n",
       "      <td>0.724648</td>\n",
       "      <td>0.801629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is_causal=True</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.711255</td>\n",
       "      <td>0.713961</td>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.781978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is_causal=True</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.706950</td>\n",
       "      <td>0.777002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mode          model  accuracy  balanced_accuracy  \\\n",
       "0    is_causal=False + head         logreg  0.855411           0.857489   \n",
       "2    is_causal=False + head        svm_rbf  0.800866           0.804322   \n",
       "3    is_causal=False + head        xgboost  0.787013           0.788717   \n",
       "1    is_causal=False + head  random_forest  0.773593           0.776275   \n",
       "6   is_causal=False + roots        svm_rbf  0.561472           0.567915   \n",
       "4   is_causal=False + roots         logreg  0.561039           0.566182   \n",
       "5   is_causal=False + roots  random_forest  0.548485           0.555309   \n",
       "7   is_causal=False + roots        xgboost  0.529004           0.533560   \n",
       "8            is_causal=True         logreg  0.734199           0.737136   \n",
       "10           is_causal=True        svm_rbf  0.720346           0.723962   \n",
       "9            is_causal=True  random_forest  0.711255           0.713961   \n",
       "11           is_causal=True        xgboost  0.709524           0.710995   \n",
       "\n",
       "          f1   roc_auc  \n",
       "0   0.850273  0.940286  \n",
       "2   0.796572  0.888548  \n",
       "3   0.782355  0.870410  \n",
       "1   0.766658  0.860990  \n",
       "6   0.556512  0.576042  \n",
       "4   0.555728  0.587825  \n",
       "5   0.544447  0.569962  \n",
       "7   0.531471  0.558644  \n",
       "8   0.734590  0.809973  \n",
       "10  0.724648  0.801629  \n",
       "9   0.708204  0.781978  \n",
       "11  0.706950  0.777002  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ok = results_df[results_df[\"status\"] == \"ok\"].copy()\n",
    "error_counts = (\n",
    "    results_df[results_df[\"status\"] == \"error\"]\n",
    "    .groupby([\"mode\", \"model\"], as_index=False)\n",
    "    .size()\n",
    ")\n",
    "\n",
    "model_mode_summary = (\n",
    "    results_ok.groupby([\"mode\", \"model\"], as_index=False)[[\"accuracy\", \"balanced_accuracy\", \"f1\", \"roc_auc\"]]\n",
    "    .mean()\n",
    "    .sort_values([\"mode\", \"accuracy\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "mode_overall_summary = (\n",
    "    results_ok.groupby(\"mode\")[[\"accuracy\", \"balanced_accuracy\", \"f1\", \"roc_auc\"]]\n",
    "    .mean()\n",
    "    .assign(mean_metric=lambda d: d.mean(axis=1))\n",
    "    .sort_values(\"mean_metric\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Successful model runs:\", len(results_ok), \"/\", len(results_df))\n",
    "if len(error_counts) > 0:\n",
    "    print(\"Model failures by mode/model:\")\n",
    "    display(error_counts)\n",
    "\n",
    "model_mode_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_causal=False + head</th>\n",
       "      <td>0.804221</td>\n",
       "      <td>0.806700</td>\n",
       "      <td>0.798964</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.824986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_causal=True</th>\n",
       "      <td>0.718831</td>\n",
       "      <td>0.721514</td>\n",
       "      <td>0.718598</td>\n",
       "      <td>0.792645</td>\n",
       "      <td>0.737897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_causal=False + roots</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.555742</td>\n",
       "      <td>0.547039</td>\n",
       "      <td>0.573118</td>\n",
       "      <td>0.556475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accuracy  balanced_accuracy        f1   roc_auc  \\\n",
       "mode                                                                       \n",
       "is_causal=False + head   0.804221           0.806700  0.798964  0.890058   \n",
       "is_causal=True           0.718831           0.721514  0.718598  0.792645   \n",
       "is_causal=False + roots  0.550000           0.555742  0.547039  0.573118   \n",
       "\n",
       "                         mean_metric  \n",
       "mode                                  \n",
       "is_causal=False + head      0.824986  \n",
       "is_causal=True              0.737897  \n",
       "is_causal=False + roots     0.556475  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_overall_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easiest generation mode by mean metric: is_causal=False + head\n",
      "(Higher means easier to classify for the selected model family and config.)\n"
     ]
    }
   ],
   "source": [
    "easiest_mode = mode_overall_summary.index[0]\n",
    "print(\"Easiest generation mode by mean metric:\", easiest_mode)\n",
    "print(\"(Higher means easier to classify for the selected model family and config.)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
