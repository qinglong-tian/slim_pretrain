{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation of `pretrain_v2` Pretrained Model\n",
        "\n",
        "This notebook evaluates `pretrain_v2/pretrained_model/latest.pt` on a small set of binary classification benchmarks.\n",
        "\n",
        "- Includes dataset types: mostly/all continuous, mixed continuous+categorical, mostly/all categorical.\n",
        "- Builds feature metadata required by the model:\n",
        "  - `feature_is_categorical`\n",
        "  - `feature_cardinalities`\n",
        "- Converts each dataset to PU format for 10 independent replicates.\n",
        "- Reports average classification + outlier-detection metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ba63ff48",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from io import BytesIO, TextIOWrapper\n",
        "import math\n",
        "import sys\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from scipy.io import arff\n",
        "from urllib.request import urlretrieve\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    average_precision_score,\n",
        "    balanced_accuracy_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7a57a9c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "repo_root=/Users/qltian/Library/CloudStorage/GoogleDrive-qltian2021@gmail.com/Other computers/My Laptop/Documents/Research/ai/slim_pretrain\n",
            "pretrain_root=/Users/qltian/Library/CloudStorage/GoogleDrive-qltian2021@gmail.com/Other computers/My Laptop/Documents/Research/ai/slim_pretrain/pretrain_v2\n"
          ]
        }
      ],
      "source": [
        "# Path resolution for both full-repo and standalone pretrain_v2 usage.\n",
        "cwd = Path.cwd().resolve()\n",
        "if (cwd / \"pretrain_v2\").exists():\n",
        "    repo_root = cwd\n",
        "    pretrain_root = cwd / \"pretrain_v2\"\n",
        "elif (cwd / \"model.py\").exists() and (cwd / \"__init__.py\").exists() and cwd.name == \"pretrain_v2\":\n",
        "    pretrain_root = cwd\n",
        "    repo_root = cwd.parent\n",
        "else:\n",
        "    raise RuntimeError(\n",
        "        \"Run this notebook either from the repo root (containing pretrain_v2/) \"\n",
        "        \"or from inside the pretrain_v2 folder.\"\n",
        "    )\n",
        "\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "\n",
        "from pretrain_v2.model import NanoTabPFNPUModel\n",
        "\n",
        "print(f\"repo_root={repo_root}\")\n",
        "print(f\"pretrain_root={pretrain_root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8a44bafa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE=mps\n",
            "CHECKPOINT_PATH=/Users/qltian/Library/CloudStorage/GoogleDrive-qltian2021@gmail.com/Other computers/My Laptop/Documents/Research/ai/slim_pretrain/pretrain_v2/pretrained_model/latest.pt\n",
            "LEGACY_CHECKPOINT_PATH=/Users/qltian/Library/CloudStorage/GoogleDrive-qltian2021@gmail.com/Other computers/My Laptop/Documents/Research/ai/slim_pretrain/pretrain_v2/saved_models/legacy_model.pt\n",
            "LEGACY_MODEL_COMMIT=bfa65b8\n"
          ]
        }
      ],
      "source": [
        "# ===== User-configurable evaluation settings =====\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    DEVICE = \"mps\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "CHECKPOINT_PATH = pretrain_root / \"pretrained_model\" / \"latest.pt\"\n",
        "LEGACY_CHECKPOINT_PATH = pretrain_root / \"saved_models\" / \"legacy_model.pt\"\n",
        "LEGACY_MODEL_COMMIT = \"bfa65b8\"\n",
        "\n",
        "OUTPUT_DIR = pretrain_root / \"evaluation_outputs\"\n",
        "CACHE_DIR = pretrain_root / \".cache\"\n",
        "\n",
        "# Download UCI Repository datasets (required for this benchmark set).\n",
        "ALLOW_UCI_DOWNLOAD = True\n",
        "\n",
        "N_REPLICATES = 10\n",
        "MAX_ATTEMPTS_PER_DATASET = 200\n",
        "\n",
        "MAX_POSITIVE_SIZE = 900\n",
        "UNLABELED_LABELED_POSITIVE_RATIO = (2, 1)  # unlabeled:labeled among selected positives\n",
        "OUTLIER_RATE = 0.13  # fraction of outliers in unlabeled set\n",
        "\n",
        "GLOBAL_SEED = 42\n",
        "\n",
        "if not CHECKPOINT_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n",
        "if not LEGACY_CHECKPOINT_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Legacy checkpoint not found: {LEGACY_CHECKPOINT_PATH}\")\n",
        "if not (0.0 <= OUTLIER_RATE < 1.0):\n",
        "    raise ValueError(\"OUTLIER_RATE must satisfy 0 <= OUTLIER_RATE < 1.\")\n",
        "\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"DEVICE={DEVICE}\")\n",
        "print(f\"CHECKPOINT_PATH={CHECKPOINT_PATH}\")\n",
        "print(f\"LEGACY_CHECKPOINT_PATH={LEGACY_CHECKPOINT_PATH}\")\n",
        "print(f\"LEGACY_MODEL_COMMIT={LEGACY_MODEL_COMMIT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7c1d3d41",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded models for comparison.\n",
            "max_categorical_classes=64\n",
            "latest model: missing_keys=0, unexpected_keys=0\n",
            "legacy model: missing_keys=0, unexpected_keys=0\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.nn.modules.transformer import LayerNorm, Linear, MultiheadAttention\n",
        "\n",
        "\n",
        "class LegacyNanoTabPFNPUModel(nn.Module):\n",
        "    \"\"\"Legacy PU-adapted NanoTabPFN model from commit bfa65b8.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        num_attention_heads: int,\n",
        "        mlp_hidden_size: int,\n",
        "        num_layers: int,\n",
        "        num_outputs: int = 2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.feature_encoder = LegacyFeatureEncoder(embedding_size)\n",
        "        self.target_encoder = LegacyTargetEncoderPU(embedding_size)\n",
        "        self.transformer_blocks = nn.ModuleList(\n",
        "            [\n",
        "                LegacyTransformerEncoderLayerPU(\n",
        "                    embedding_size=embedding_size,\n",
        "                    nhead=num_attention_heads,\n",
        "                    mlp_hidden_size=mlp_hidden_size,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.decoder = LegacyDecoder(embedding_size, mlp_hidden_size, num_outputs)\n",
        "\n",
        "    def forward(self, src: tuple[torch.Tensor, torch.Tensor], train_test_split_index: int) -> torch.Tensor:\n",
        "        x_src, y_src = src\n",
        "        if len(y_src.shape) < len(x_src.shape):\n",
        "            y_src = y_src.unsqueeze(-1)\n",
        "\n",
        "        x_src = self.feature_encoder(x_src, train_test_split_index)\n",
        "        num_rows = x_src.shape[1]\n",
        "        y_src = self.target_encoder(y_src, num_rows)\n",
        "        src_table = torch.cat([x_src, y_src], dim=2)\n",
        "\n",
        "        for block in self.transformer_blocks:\n",
        "            src_table = block(src_table, train_test_split_index=train_test_split_index)\n",
        "\n",
        "        output = src_table[:, train_test_split_index:, -1, :]\n",
        "        return self.decoder(output)\n",
        "\n",
        "\n",
        "class LegacyFeatureEncoder(nn.Module):\n",
        "    def __init__(self, embedding_size: int):\n",
        "        super().__init__()\n",
        "        self.linear_layer = nn.Linear(1, embedding_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, train_test_split_index: int) -> torch.Tensor:\n",
        "        x = x.unsqueeze(-1)\n",
        "        train_rows = int(max(0, min(train_test_split_index, x.shape[1])))\n",
        "        if train_rows >= 2:\n",
        "            train_slice = x[:, :train_rows]\n",
        "            mean = torch.mean(train_slice, dim=1, keepdim=True)\n",
        "            std = torch.std(train_slice, dim=1, keepdim=True, unbiased=False).clamp_min(1e-20)\n",
        "        elif train_rows == 1:\n",
        "            train_slice = x[:, :1]\n",
        "            mean = torch.mean(train_slice, dim=1, keepdim=True)\n",
        "            std = torch.ones_like(mean)\n",
        "        else:\n",
        "            mean = torch.zeros_like(x[:, :1])\n",
        "            std = torch.ones_like(x[:, :1])\n",
        "        x = (x - mean) / std\n",
        "        x = torch.clip(x, min=-100, max=100)\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "\n",
        "class LegacyTargetEncoderPU(nn.Module):\n",
        "    def __init__(self, embedding_size: int):\n",
        "        super().__init__()\n",
        "        self.linear_layer = nn.Linear(1, embedding_size)\n",
        "        self.unlabeled_embedding = nn.Parameter(torch.zeros(1, 1, embedding_size))\n",
        "        nn.init.normal_(self.unlabeled_embedding, std=0.02)\n",
        "\n",
        "    def forward(self, y_train: torch.Tensor, num_rows: int) -> torch.Tensor:\n",
        "        if y_train.dim() == 2:\n",
        "            y_train = y_train.unsqueeze(-1)\n",
        "        if y_train.shape[1] > num_rows:\n",
        "            raise ValueError(\"y_train rows exceed total num_rows.\")\n",
        "\n",
        "        batch_size = y_train.shape[0]\n",
        "        pad_rows = num_rows - y_train.shape[1]\n",
        "        if pad_rows > 0:\n",
        "            padding = torch.full(\n",
        "                (batch_size, pad_rows, 1),\n",
        "                -1.0,\n",
        "                dtype=y_train.dtype,\n",
        "                device=y_train.device,\n",
        "            )\n",
        "            y_full = torch.cat([y_train, padding], dim=1)\n",
        "        else:\n",
        "            y_full = y_train\n",
        "\n",
        "        observed_mask = y_full >= 0\n",
        "        y_for_linear = y_full.clone()\n",
        "        y_for_linear[~observed_mask] = 0.0\n",
        "        embedded = self.linear_layer(y_for_linear)\n",
        "\n",
        "        unlabeled = self.unlabeled_embedding.expand(batch_size, num_rows, -1)\n",
        "        embedded = torch.where(observed_mask.expand_as(embedded), embedded, unlabeled)\n",
        "        return embedded.unsqueeze(2)\n",
        "\n",
        "\n",
        "class LegacyTransformerEncoderLayerPU(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        nhead: int,\n",
        "        mlp_hidden_size: int,\n",
        "        layer_norm_eps: float = 1e-5,\n",
        "        batch_first: bool = True,\n",
        "        device=None,\n",
        "        dtype=None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.self_attention_between_datapoints = MultiheadAttention(\n",
        "            embedding_size, nhead, batch_first=batch_first, device=device, dtype=dtype\n",
        "        )\n",
        "        self.self_attention_between_features = MultiheadAttention(\n",
        "            embedding_size, nhead, batch_first=batch_first, device=device, dtype=dtype\n",
        "        )\n",
        "\n",
        "        self.linear1 = Linear(embedding_size, mlp_hidden_size, device=device, dtype=dtype)\n",
        "        self.linear2 = Linear(mlp_hidden_size, embedding_size, device=device, dtype=dtype)\n",
        "\n",
        "        self.norm1 = LayerNorm(embedding_size, eps=layer_norm_eps, device=device, dtype=dtype)\n",
        "        self.norm2 = LayerNorm(embedding_size, eps=layer_norm_eps, device=device, dtype=dtype)\n",
        "        self.norm3 = LayerNorm(embedding_size, eps=layer_norm_eps, device=device, dtype=dtype)\n",
        "\n",
        "    def forward(self, src: torch.Tensor, train_test_split_index: int) -> torch.Tensor:\n",
        "        batch_size, rows_size, col_size, embedding_size = src.shape\n",
        "\n",
        "        src_f = src.reshape(batch_size * rows_size, col_size, embedding_size)\n",
        "        src_f = self.self_attention_between_features(src_f, src_f, src_f)[0] + src_f\n",
        "        src = src_f.reshape(batch_size, rows_size, col_size, embedding_size)\n",
        "        src = self.norm1(src)\n",
        "\n",
        "        src = src.transpose(1, 2)\n",
        "        src_d = src.reshape(batch_size * col_size, rows_size, embedding_size)\n",
        "\n",
        "        src_left = self.self_attention_between_datapoints(\n",
        "            src_d[:, :train_test_split_index],\n",
        "            src_d[:, :train_test_split_index],\n",
        "            src_d[:, :train_test_split_index],\n",
        "        )[0]\n",
        "        src_right = self.self_attention_between_datapoints(\n",
        "            src_d[:, train_test_split_index:],\n",
        "            src_d,\n",
        "            src_d,\n",
        "        )[0]\n",
        "        src_d = torch.cat([src_left, src_right], dim=1) + src_d\n",
        "\n",
        "        src = src_d.reshape(batch_size, col_size, rows_size, embedding_size)\n",
        "        src = src.transpose(2, 1)\n",
        "        src = self.norm2(src)\n",
        "\n",
        "        src = self.linear2(F.gelu(self.linear1(src))) + src\n",
        "        src = self.norm3(src)\n",
        "        return src\n",
        "\n",
        "\n",
        "class LegacyDecoder(nn.Module):\n",
        "    def __init__(self, embedding_size: int, mlp_hidden_size: int, num_outputs: int):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(embedding_size, mlp_hidden_size)\n",
        "        self.linear2 = nn.Linear(mlp_hidden_size, num_outputs)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear2(F.gelu(self.linear1(x)))\n",
        "\n",
        "\n",
        "def load_latest_model_from_checkpoint(checkpoint_path: Path, device: str = \"cpu\"):\n",
        "    payload = torch.load(checkpoint_path, map_location=device)\n",
        "    model_cfg = payload.get(\"config\", {}).get(\"model\", {})\n",
        "\n",
        "    model = NanoTabPFNPUModel(\n",
        "        embedding_size=int(model_cfg.get(\"embedding_size\", 128)),\n",
        "        num_attention_heads=int(model_cfg.get(\"num_attention_heads\", 8)),\n",
        "        mlp_hidden_size=int(model_cfg.get(\"mlp_hidden_size\", 256)),\n",
        "        num_layers=int(model_cfg.get(\"num_layers\", 6)),\n",
        "        num_outputs=int(model_cfg.get(\"num_outputs\", 2)),\n",
        "        max_categorical_classes=int(model_cfg.get(\"max_categorical_classes\", 64)),\n",
        "    ).to(device)\n",
        "\n",
        "    state_dict = payload.get(\"model_state_dict\", payload)\n",
        "    load_result = model.load_state_dict(state_dict, strict=False)\n",
        "    model.eval()\n",
        "    return model, payload, load_result\n",
        "\n",
        "\n",
        "def load_legacy_model_from_checkpoint(checkpoint_path: Path, device: str = \"cpu\"):\n",
        "    payload = torch.load(checkpoint_path, map_location=device)\n",
        "    model_cfg = payload.get(\"config\", {}).get(\"model\", {})\n",
        "\n",
        "    model = LegacyNanoTabPFNPUModel(\n",
        "        embedding_size=int(model_cfg.get(\"embedding_size\", 128)),\n",
        "        num_attention_heads=int(model_cfg.get(\"num_attention_heads\", 8)),\n",
        "        mlp_hidden_size=int(model_cfg.get(\"mlp_hidden_size\", 256)),\n",
        "        num_layers=int(model_cfg.get(\"num_layers\", 6)),\n",
        "        num_outputs=int(model_cfg.get(\"num_outputs\", 2)),\n",
        "    ).to(device)\n",
        "\n",
        "    state_dict = payload.get(\"model_state_dict\", payload)\n",
        "    load_result = model.load_state_dict(state_dict, strict=False)\n",
        "    model.eval()\n",
        "    return model, payload, load_result\n",
        "\n",
        "\n",
        "latest_model, latest_payload, latest_load_result = load_latest_model_from_checkpoint(CHECKPOINT_PATH, device=DEVICE)\n",
        "legacy_model, legacy_payload, legacy_load_result = load_legacy_model_from_checkpoint(LEGACY_CHECKPOINT_PATH, device=DEVICE)\n",
        "\n",
        "MAX_CATEGORICAL_CLASSES = int(latest_model.feature_encoder.categorical_embedding.num_embeddings - 1)\n",
        "\n",
        "MODEL_SPECS = [\n",
        "    {\n",
        "        \"model_name\": \"latest\",\n",
        "        \"model\": latest_model,\n",
        "        \"supports_categorical\": True,\n",
        "        \"checkpoint_path\": str(CHECKPOINT_PATH),\n",
        "    },\n",
        "    {\n",
        "        \"model_name\": \"legacy\",\n",
        "        \"model\": legacy_model,\n",
        "        \"supports_categorical\": False,\n",
        "        \"checkpoint_path\": str(LEGACY_CHECKPOINT_PATH),\n",
        "    },\n",
        "]\n",
        "\n",
        "print(\"Loaded models for comparison.\")\n",
        "print(f\"max_categorical_classes={MAX_CATEGORICAL_CLASSES}\")\n",
        "print(\n",
        "    \"latest model: \"\n",
        "    f\"missing_keys={len(latest_load_result.missing_keys)}, unexpected_keys={len(latest_load_result.unexpected_keys)}\"\n",
        ")\n",
        "print(\n",
        "    \"legacy model: \"\n",
        "    f\"missing_keys={len(legacy_load_result.missing_keys)}, unexpected_keys={len(legacy_load_result.unexpected_keys)}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "76697466",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>source</th>\n",
              "      <th>rows</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uci_wdbc_continuous</td>\n",
              "      <td>uci:wdbc</td>\n",
              "      <td>569</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>uci_adult_mixed</td>\n",
              "      <td>uci:adult</td>\n",
              "      <td>30162</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uci_spambase_continuous</td>\n",
              "      <td>uci:spambase</td>\n",
              "      <td>4601</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uci_mushroom_categorical</td>\n",
              "      <td>uci:mushroom</td>\n",
              "      <td>8124</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uci_magic_gamma_continuous</td>\n",
              "      <td>uci:magic-gamma-telescope</td>\n",
              "      <td>19020</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>uci_car_evaluation_categorical</td>\n",
              "      <td>uci:car-evaluation</td>\n",
              "      <td>1728</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>uci_banknote_authentication_continuous</td>\n",
              "      <td>uci:banknote-authentication</td>\n",
              "      <td>1372</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>uci_rice_cammeo_osmancik_continuous</td>\n",
              "      <td>uci:rice-cammeo-and-osmancik</td>\n",
              "      <td>3810</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>uci_default_credit_card_clients_continuous</td>\n",
              "      <td>uci:default-of-credit-card-clients</td>\n",
              "      <td>30000</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>uci_abalone_binary_rings_cutoff</td>\n",
              "      <td>uci:abalone</td>\n",
              "      <td>4177</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>uci_letter_recognition_C_vs_U</td>\n",
              "      <td>uci:letter-recognition</td>\n",
              "      <td>1549</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       dataset  \\\n",
              "0                          uci_wdbc_continuous   \n",
              "1                              uci_adult_mixed   \n",
              "2                      uci_spambase_continuous   \n",
              "3                     uci_mushroom_categorical   \n",
              "4                   uci_magic_gamma_continuous   \n",
              "5               uci_car_evaluation_categorical   \n",
              "6       uci_banknote_authentication_continuous   \n",
              "7          uci_rice_cammeo_osmancik_continuous   \n",
              "8   uci_default_credit_card_clients_continuous   \n",
              "9              uci_abalone_binary_rings_cutoff   \n",
              "10               uci_letter_recognition_C_vs_U   \n",
              "\n",
              "                                source   rows  features  \n",
              "0                             uci:wdbc    569        30  \n",
              "1                            uci:adult  30162        14  \n",
              "2                         uci:spambase   4601        57  \n",
              "3                         uci:mushroom   8124        21  \n",
              "4            uci:magic-gamma-telescope  19020        10  \n",
              "5                   uci:car-evaluation   1728         6  \n",
              "6          uci:banknote-authentication   1372         4  \n",
              "7         uci:rice-cammeo-and-osmancik   3810         7  \n",
              "8   uci:default-of-credit-card-clients  30000        23  \n",
              "9                          uci:abalone   4177         8  \n",
              "10              uci:letter-recognition   1549        16  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "UCI_BASE_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases\"\n",
        "\n",
        "\n",
        "def _download_with_cache(url: str, subdir: str, filename: str, allow_download: bool = True) -> Path:\n",
        "    target_dir = CACHE_DIR / \"uci\" / subdir\n",
        "    target_dir.mkdir(parents=True, exist_ok=True)\n",
        "    local_path = target_dir / filename\n",
        "\n",
        "    if local_path.exists():\n",
        "        return local_path\n",
        "    if not allow_download:\n",
        "        raise FileNotFoundError(\n",
        "            f\"UCI cached file not found and downloads are disabled: {local_path}. \"\n",
        "            \"Set ALLOW_UCI_DOWNLOAD=True to fetch it.\"\n",
        "        )\n",
        "\n",
        "    urlretrieve(url, local_path)\n",
        "    return local_path\n",
        "\n",
        "\n",
        "def _strip_object_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    object_cols = df.select_dtypes(include=[\"object\", \"string\"]).columns\n",
        "    for col in object_cols:\n",
        "        df[col] = df[col].astype(\"string\").str.strip()\n",
        "    return df\n",
        "\n",
        "\n",
        "def _read_uci_table_from_zip(zip_path: Path) -> pd.DataFrame:\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "        members = [\n",
        "            name\n",
        "            for name in zf.namelist()\n",
        "            if not name.endswith(\"/\") and not name.lower().startswith(\"__macosx/\")\n",
        "        ]\n",
        "        if len(members) == 0:\n",
        "            raise FileNotFoundError(f\"No data files found in zip: {zip_path}\")\n",
        "\n",
        "        preferred_exts = (\".csv\", \".arff\", \".data\", \".txt\", \".xlsx\", \".xls\")\n",
        "        ordered_members = []\n",
        "        for ext in preferred_exts:\n",
        "            ordered_members.extend([name for name in members if name.lower().endswith(ext)])\n",
        "        ordered_members.extend([name for name in members if name not in ordered_members])\n",
        "\n",
        "        last_error = None\n",
        "        for selected in ordered_members:\n",
        "            try:\n",
        "                with zf.open(selected) as f:\n",
        "                    lower = selected.lower()\n",
        "                    if lower.endswith(\".csv\"):\n",
        "                        df = pd.read_csv(f)\n",
        "                    elif lower.endswith(\".arff\"):\n",
        "                        with TextIOWrapper(f, encoding=\"utf-8\", errors=\"ignore\") as txt_f:\n",
        "                            data, _ = arff.loadarff(txt_f)\n",
        "                        df = pd.DataFrame(data)\n",
        "                        for col in df.columns:\n",
        "                            if df[col].dtype == object:\n",
        "                                df[col] = df[col].apply(\n",
        "                                    lambda value: value.decode(\"utf-8\") if isinstance(value, (bytes, bytearray)) else value\n",
        "                                )\n",
        "                    elif lower.endswith(\".xlsx\") or lower.endswith(\".xls\"):\n",
        "                        df = pd.read_excel(BytesIO(f.read()))\n",
        "                    else:\n",
        "                        df = pd.read_csv(f)\n",
        "                return _strip_object_columns(df)\n",
        "            except Exception as exc:\n",
        "                last_error = exc\n",
        "\n",
        "        raise RuntimeError(f\"Failed to parse any file from zip: {zip_path}\") from last_error\n",
        "\n",
        "\n",
        "def get_benchmark_datasets(allow_uci_download: bool = True, binary_seed: int = 42):\n",
        "    datasets = []\n",
        "    root_missing_drop_threshold = 0.20\n",
        "\n",
        "    # 1) UCI Breast Cancer Wisconsin (Diagnostic)\n",
        "    # - Remove ID column.\n",
        "    # - All features are continuous.\n",
        "    wdbc_feature_names = [\n",
        "        \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\",\n",
        "        \"compactness_mean\", \"concavity_mean\", \"concave_points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\",\n",
        "        \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \"smoothness_se\",\n",
        "        \"compactness_se\", \"concavity_se\", \"concave_points_se\", \"symmetry_se\", \"fractal_dimension_se\",\n",
        "        \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\",\n",
        "        \"compactness_worst\", \"concavity_worst\", \"concave_points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\",\n",
        "    ]\n",
        "    wdbc_cols = [\"id\", \"target\"] + wdbc_feature_names\n",
        "    wdbc_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/breast-cancer-wisconsin/wdbc.data\",\n",
        "        subdir=\"wdbc\",\n",
        "        filename=\"wdbc.data\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    wdbc_df = pd.read_csv(wdbc_path, header=None, names=wdbc_cols)\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_wdbc_continuous\",\n",
        "            \"source\": \"uci:wdbc\",\n",
        "            \"X\": wdbc_df[wdbc_feature_names].copy(),\n",
        "            \"y\": wdbc_df[\"target\"].copy(),\n",
        "            \"schema_hint\": {\"force_all_continuous\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 2) UCI Adult\n",
        "    # - Drop rows with any missing values.\n",
        "    # - Treat only Categorical/Binary variables as categorical.\n",
        "    # - Treat Integer variables as continuous.\n",
        "    adult_cols = [\n",
        "        \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\",\n",
        "        \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\",\n",
        "        \"hours_per_week\", \"native_country\", \"target\",\n",
        "    ]\n",
        "    adult_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/adult/adult.data\",\n",
        "        subdir=\"adult\",\n",
        "        filename=\"adult.data\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    adult_df = pd.read_csv(adult_path, header=None, names=adult_cols, na_values=[\"?\"], skipinitialspace=True)\n",
        "    adult_df = _strip_object_columns(adult_df)\n",
        "    adult_df = adult_df.dropna(axis=0).reset_index(drop=True)\n",
        "\n",
        "    adult_categorical_cols = [\n",
        "        \"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\",\n",
        "        \"race\", \"sex\", \"native_country\",\n",
        "    ]\n",
        "    adult_feature_cols = [col for col in adult_cols if col != \"target\"]\n",
        "    adult_continuous_cols = [col for col in adult_feature_cols if col not in adult_categorical_cols]\n",
        "\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_adult_mixed\",\n",
        "            \"source\": \"uci:adult\",\n",
        "            \"X\": adult_df[adult_feature_cols].copy(),\n",
        "            \"y\": adult_df[\"target\"].copy(),\n",
        "            \"schema_hint\": {\n",
        "                \"force_categorical_cols\": adult_categorical_cols,\n",
        "                \"force_continuous_cols\": adult_continuous_cols,\n",
        "            },\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 3) UCI Spambase - all continuous\n",
        "    spambase_cols = [f\"f{i}\" for i in range(1, 58)] + [\"target\"]\n",
        "    spambase_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/spambase/spambase.data\",\n",
        "        subdir=\"spambase\",\n",
        "        filename=\"spambase.data\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    spambase_df = pd.read_csv(spambase_path, header=None, names=spambase_cols)\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_spambase_continuous\",\n",
        "            \"source\": \"uci:spambase\",\n",
        "            \"X\": spambase_df[[f\"f{i}\" for i in range(1, 58)]].copy(),\n",
        "            \"y\": spambase_df[\"target\"].copy(),\n",
        "            \"schema_hint\": {\"force_all_continuous\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 4) UCI Mushroom - all categorical\n",
        "    # - Drop stalk-root if its missing rate is high; then drop remaining missing rows.\n",
        "    mushroom_feature_cols = [\n",
        "        \"cap_shape\", \"cap_surface\", \"cap_color\", \"bruises\", \"odor\",\n",
        "        \"gill_attachment\", \"gill_spacing\", \"gill_size\", \"gill_color\", \"stalk_shape\",\n",
        "        \"stalk_root\", \"stalk_surface_above_ring\", \"stalk_surface_below_ring\",\n",
        "        \"stalk_color_above_ring\", \"stalk_color_below_ring\", \"veil_type\", \"veil_color\",\n",
        "        \"ring_number\", \"ring_type\", \"spore_print_color\", \"population\", \"habitat\",\n",
        "    ]\n",
        "    mushroom_cols = [\"target\"] + mushroom_feature_cols\n",
        "    mushroom_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/mushroom/agaricus-lepiota.data\",\n",
        "        subdir=\"mushroom\",\n",
        "        filename=\"agaricus-lepiota.data\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    mushroom_df = pd.read_csv(mushroom_path, header=None, names=mushroom_cols, na_values=[\"?\"], skipinitialspace=True)\n",
        "    mushroom_df = _strip_object_columns(mushroom_df)\n",
        "\n",
        "    stalk_root_missing_rate = float(mushroom_df[\"stalk_root\"].isna().mean())\n",
        "    if stalk_root_missing_rate > root_missing_drop_threshold:\n",
        "        mushroom_df = mushroom_df.drop(columns=[\"stalk_root\"])\n",
        "\n",
        "    mushroom_df = mushroom_df.dropna(axis=0).reset_index(drop=True)\n",
        "    mushroom_X_cols = [col for col in mushroom_df.columns if col != \"target\"]\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_mushroom_categorical\",\n",
        "            \"source\": \"uci:mushroom\",\n",
        "            \"X\": mushroom_df[mushroom_X_cols].copy(),\n",
        "            \"y\": mushroom_df[\"target\"].copy(),\n",
        "            \"schema_hint\": {\"force_all_categorical\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 5) UCI MAGIC Gamma Telescope - all continuous\n",
        "    magic_feature_cols = [\n",
        "        \"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\",\n",
        "        \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\",\n",
        "    ]\n",
        "    magic_cols = magic_feature_cols + [\"target\"]\n",
        "    magic_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/magic/magic04.data\",\n",
        "        subdir=\"magic_gamma_telescope\",\n",
        "        filename=\"magic04.data\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    magic_df = pd.read_csv(magic_path, header=None, names=magic_cols)\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_magic_gamma_continuous\",\n",
        "            \"source\": \"uci:magic-gamma-telescope\",\n",
        "            \"X\": magic_df[magic_feature_cols].copy(),\n",
        "            \"y\": magic_df[\"target\"].copy(),\n",
        "            \"schema_hint\": {\"force_all_continuous\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 6) UCI Car Evaluation - all categorical\n",
        "    # Target mapping: {unacc, acc} vs {good, vgood}\n",
        "    car_cols = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"target\"]\n",
        "    car_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/car/car.data\",\n",
        "        subdir=\"car_evaluation\",\n",
        "        filename=\"car.data\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    car_df = pd.read_csv(car_path, header=None, names=car_cols)\n",
        "    car_df = _strip_object_columns(car_df)\n",
        "\n",
        "    car_binary_target = car_df[\"target\"].map(\n",
        "        {\n",
        "            \"unacc\": \"unacc_or_acc\",\n",
        "            \"acc\": \"unacc_or_acc\",\n",
        "            \"good\": \"good_or_vgood\",\n",
        "            \"vgood\": \"good_or_vgood\",\n",
        "        }\n",
        "    )\n",
        "    car_valid = car_binary_target.notna()\n",
        "    car_df = car_df.loc[car_valid].reset_index(drop=True)\n",
        "    car_binary_target = car_binary_target.loc[car_valid].reset_index(drop=True)\n",
        "\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_car_evaluation_categorical\",\n",
        "            \"source\": \"uci:car-evaluation\",\n",
        "            \"X\": car_df[[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]].copy(),\n",
        "            \"y\": car_binary_target,\n",
        "            \"schema_hint\": {\"force_all_categorical\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 7) UCI Banknote Authentication - all continuous\n",
        "    banknote_cols = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"target\"]\n",
        "    banknote_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/data_banknote_authentication/data_banknote_authentication.txt\",\n",
        "        subdir=\"banknote_authentication\",\n",
        "        filename=\"data_banknote_authentication.txt\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    banknote_df = pd.read_csv(banknote_path, header=None, names=banknote_cols)\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_banknote_authentication_continuous\",\n",
        "            \"source\": \"uci:banknote-authentication\",\n",
        "            \"X\": banknote_df[[\"variance\", \"skewness\", \"curtosis\", \"entropy\"]].copy(),\n",
        "            \"y\": banknote_df[\"target\"].copy(),\n",
        "            \"schema_hint\": {\"force_all_continuous\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 8) UCI Rice (Cammeo and Osmancik) - all continuous (including integer columns)\n",
        "    rice_zip_path = _download_with_cache(\n",
        "        \"https://archive.ics.uci.edu/static/public/545/rice+cammeo+and+osmancik.zip\",\n",
        "        subdir=\"rice_cammeo_osmancik\",\n",
        "        filename=\"rice+cammeo+and+osmancik.zip\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    rice_df = _read_uci_table_from_zip(rice_zip_path)\n",
        "    rice_target_col = next(\n",
        "        (candidate for candidate in [\"Class\", \"class\", \"target\", \"Target\"] if candidate in rice_df.columns),\n",
        "        rice_df.columns[-1],\n",
        "    )\n",
        "    rice_feature_cols = [col for col in rice_df.columns if col != rice_target_col]\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_rice_cammeo_osmancik_continuous\",\n",
        "            \"source\": \"uci:rice-cammeo-and-osmancik\",\n",
        "            \"X\": rice_df[rice_feature_cols].copy(),\n",
        "            \"y\": rice_df[rice_target_col].copy(),\n",
        "            \"schema_hint\": {\"force_all_continuous\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 9) UCI Default of Credit Card Clients - all continuous, remove ID column\n",
        "    default_credit_zip_path = _download_with_cache(\n",
        "        \"https://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip\",\n",
        "        subdir=\"default_credit_card_clients\",\n",
        "        filename=\"default+of+credit+card+clients.zip\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    default_credit_df = _read_uci_table_from_zip(default_credit_zip_path)\n",
        "    default_credit_df = _strip_object_columns(default_credit_df)\n",
        "\n",
        "    def _normalize_col_name(col_name: object) -> str:\n",
        "        text = str(col_name).strip().lower()\n",
        "        text = \"\".join(ch if ch.isalnum() else \"_\" for ch in text)\n",
        "        while \"__\" in text:\n",
        "            text = text.replace(\"__\", \"_\")\n",
        "        return text.strip(\"_\")\n",
        "\n",
        "    def _is_placeholder_col_name(col_name: object) -> bool:\n",
        "        norm = _normalize_col_name(col_name)\n",
        "        return norm.startswith(\"unnamed\") or norm.isdigit()\n",
        "\n",
        "    # If parser produced placeholder columns and first row looks like the true header, promote it.\n",
        "    if default_credit_df.shape[0] > 0:\n",
        "        first_row_norm = [_normalize_col_name(v) for v in default_credit_df.iloc[0].tolist()]\n",
        "        header_keywords = {\"id\", \"y\", \"limit_bal\", \"pay_0\", \"bill_amt1\", \"default_payment_next_month\"}\n",
        "        placeholder_cols = all(_is_placeholder_col_name(col) for col in default_credit_df.columns)\n",
        "        if placeholder_cols or len(header_keywords & set(first_row_norm)) >= 2:\n",
        "            default_credit_df.columns = default_credit_df.iloc[0].astype(str).tolist()\n",
        "            default_credit_df = default_credit_df.iloc[1:].reset_index(drop=True)\n",
        "            default_credit_df = _strip_object_columns(default_credit_df)\n",
        "\n",
        "    # Remove duplicated header-like first row if present after parsing.\n",
        "    if default_credit_df.shape[0] > 0:\n",
        "        first_row = default_credit_df.iloc[0].astype(\"string\").str.lower().tolist()\n",
        "        col_tokens = [str(col).strip().lower() for col in default_credit_df.columns.tolist()]\n",
        "        if sum(int(a == b) for a, b in zip(first_row, col_tokens)) >= max(3, len(col_tokens) // 2):\n",
        "            default_credit_df = default_credit_df.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "    normalized_to_original = {_normalize_col_name(col): col for col in default_credit_df.columns}\n",
        "    # Per dataset spec, prefer target variable Y.\n",
        "    preferred_norm_names = [\n",
        "        \"y\",\n",
        "        \"default_payment_next_month\",\n",
        "        \"defaultpaymentnextmonth\",\n",
        "        \"target\",\n",
        "    ]\n",
        "    default_credit_target_col = next(\n",
        "        (normalized_to_original[name] for name in preferred_norm_names if name in normalized_to_original),\n",
        "        None,\n",
        "    )\n",
        "\n",
        "    if default_credit_target_col is None:\n",
        "        contains_default_cols = [\n",
        "            col\n",
        "            for col in default_credit_df.columns\n",
        "            if \"default\" in _normalize_col_name(col) and \"month\" in _normalize_col_name(col)\n",
        "        ]\n",
        "        if len(contains_default_cols) > 0:\n",
        "            default_credit_target_col = contains_default_cols[0]\n",
        "\n",
        "    if default_credit_target_col is None:\n",
        "        binary_cols = [\n",
        "            col\n",
        "            for col in default_credit_df.columns\n",
        "            if int(pd.Series(default_credit_df[col]).nunique(dropna=True)) == 2\n",
        "        ]\n",
        "        named_binary_cols = [\n",
        "            col\n",
        "            for col in binary_cols\n",
        "            if _normalize_col_name(col) in {\"y\", \"target\"} or \"default\" in _normalize_col_name(col)\n",
        "        ]\n",
        "        if len(named_binary_cols) > 0:\n",
        "            default_credit_target_col = named_binary_cols[0]\n",
        "        elif len(binary_cols) > 0:\n",
        "            default_credit_target_col = binary_cols[-1]\n",
        "\n",
        "    if default_credit_target_col is None:\n",
        "        raise ValueError(\"Could not infer target column for default credit dataset.\")\n",
        "\n",
        "    default_credit_target = pd.to_numeric(default_credit_df[default_credit_target_col], errors=\"coerce\")\n",
        "    valid_target = default_credit_target.notna()\n",
        "    default_credit_df = default_credit_df.loc[valid_target].reset_index(drop=True)\n",
        "    default_credit_target = default_credit_target.loc[valid_target].reset_index(drop=True)\n",
        "\n",
        "    if int(default_credit_target.nunique(dropna=True)) != 2:\n",
        "        unique_counts = {\n",
        "            str(col): int(pd.Series(default_credit_df[col]).nunique(dropna=True))\n",
        "            for col in default_credit_df.columns\n",
        "        }\n",
        "        raise ValueError(\n",
        "            \"Default credit target is not binary after parsing. \"\n",
        "            f\"Selected target column={default_credit_target_col!r}, \"\n",
        "            f\"num_classes={int(default_credit_target.nunique(dropna=True))}, \"\n",
        "            f\"column_nunique={unique_counts}\"\n",
        "        )\n",
        "\n",
        "    default_credit_feature_cols = [\n",
        "        col\n",
        "        for col in default_credit_df.columns\n",
        "        if col != default_credit_target_col and _normalize_col_name(col) != \"id\"\n",
        "    ]\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_default_credit_card_clients_continuous\",\n",
        "            \"source\": \"uci:default-of-credit-card-clients\",\n",
        "            \"X\": default_credit_df[default_credit_feature_cols].copy(),\n",
        "            \"y\": default_credit_target.astype(np.int64).copy(),\n",
        "            \"schema_hint\": {\"force_all_continuous\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 10) UCI Abalone - convert Rings to binary using a data-driven cutoff (median Rings)\n",
        "    abalone_cols = [\n",
        "        \"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole_weight\", \"Shucked_weight\",\n",
        "        \"Viscera_weight\", \"Shell_weight\", \"Rings\",\n",
        "    ]\n",
        "    abalone_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/abalone/abalone.data\",\n",
        "        subdir=\"abalone\",\n",
        "        filename=\"abalone.data\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    abalone_df = pd.read_csv(abalone_path, header=None, names=abalone_cols)\n",
        "    abalone_df = _strip_object_columns(abalone_df)\n",
        "\n",
        "    rings_series = pd.to_numeric(abalone_df[\"Rings\"], errors=\"coerce\")\n",
        "    rings_cutoff = int(np.nanmedian(rings_series.to_numpy()))\n",
        "    abalone_binary_target = np.where(rings_series >= rings_cutoff, f\"rings_ge_{rings_cutoff}\", f\"rings_lt_{rings_cutoff}\")\n",
        "\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": \"uci_abalone_binary_rings_cutoff\",\n",
        "            \"source\": \"uci:abalone\",\n",
        "            \"X\": abalone_df[[c for c in abalone_cols if c != \"Rings\"]].copy(),\n",
        "            \"y\": pd.Series(abalone_binary_target),\n",
        "            \"schema_hint\": {},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 11) UCI Letter Recognition - randomly choose two letter classes for binary classification\n",
        "    letter_cols = [\"target\"] + [f\"x{i}\" for i in range(1, 17)]\n",
        "    letter_path = _download_with_cache(\n",
        "        f\"{UCI_BASE_URL}/letter-recognition/letter-recognition.data\",\n",
        "        subdir=\"letter_recognition\",\n",
        "        filename=\"letter-recognition.data\",\n",
        "        allow_download=allow_uci_download,\n",
        "    )\n",
        "    letter_df = pd.read_csv(letter_path, header=None, names=letter_cols)\n",
        "    letter_df = _strip_object_columns(letter_df)\n",
        "\n",
        "    letter_classes = np.array(sorted(letter_df[\"target\"].dropna().unique().tolist()), dtype=object)\n",
        "    if letter_classes.shape[0] < 2:\n",
        "        raise ValueError(\"Letter Recognition dataset must have at least two classes.\")\n",
        "    class_rng = np.random.default_rng(int(binary_seed))\n",
        "    chosen_classes = class_rng.choice(letter_classes, size=2, replace=False)\n",
        "    chosen_classes = np.sort(chosen_classes)\n",
        "\n",
        "    letter_two_class_df = letter_df[letter_df[\"target\"].isin(chosen_classes)].reset_index(drop=True)\n",
        "    letter_binary_target = np.where(\n",
        "        letter_two_class_df[\"target\"].to_numpy() == chosen_classes[0],\n",
        "        f\"letter_{chosen_classes[0]}\",\n",
        "        f\"letter_{chosen_classes[1]}\",\n",
        "    )\n",
        "\n",
        "    datasets.append(\n",
        "        {\n",
        "            \"name\": f\"uci_letter_recognition_{chosen_classes[0]}_vs_{chosen_classes[1]}\",\n",
        "            \"source\": \"uci:letter-recognition\",\n",
        "            \"X\": letter_two_class_df[[f\"x{i}\" for i in range(1, 17)]].copy(),\n",
        "            \"y\": pd.Series(letter_binary_target),\n",
        "            \"schema_hint\": {\"force_all_continuous\": True},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return datasets\n",
        "\n",
        "\n",
        "benchmark_datasets = get_benchmark_datasets(allow_uci_download=ALLOW_UCI_DOWNLOAD, binary_seed=GLOBAL_SEED)\n",
        "pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"dataset\": d[\"name\"],\n",
        "            \"source\": d[\"source\"],\n",
        "            \"rows\": int(d[\"X\"].shape[0]),\n",
        "            \"features\": int(d[\"X\"].shape[1]),\n",
        "        }\n",
        "        for d in benchmark_datasets\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "70106eef",
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer_feature_schema(df: pd.DataFrame, schema_hint: Optional[Dict] = None) -> Dict[str, str]:\n",
        "    schema_hint = schema_hint or {}\n",
        "    force_all_categorical = bool(schema_hint.get(\"force_all_categorical\", False))\n",
        "    force_all_continuous = bool(schema_hint.get(\"force_all_continuous\", False))\n",
        "    force_categorical_cols = set(schema_hint.get(\"force_categorical_cols\", []))\n",
        "    force_continuous_cols = set(schema_hint.get(\"force_continuous_cols\", []))\n",
        "\n",
        "    if force_all_categorical and force_all_continuous:\n",
        "        raise ValueError(\"Cannot force all features to both categorical and continuous.\")\n",
        "    overlap = force_categorical_cols & force_continuous_cols\n",
        "    if len(overlap) > 0:\n",
        "        raise ValueError(f\"Columns listed as both categorical and continuous: {sorted(overlap)}\")\n",
        "\n",
        "    schema: Dict[str, str] = {}\n",
        "    for col in df.columns:\n",
        "        s = df[col]\n",
        "        if force_all_categorical:\n",
        "            schema[col] = \"categorical\"\n",
        "            continue\n",
        "        if force_all_continuous:\n",
        "            schema[col] = \"continuous\"\n",
        "            continue\n",
        "        if col in force_continuous_cols:\n",
        "            schema[col] = \"continuous\"\n",
        "            continue\n",
        "        if col in force_categorical_cols:\n",
        "            schema[col] = \"categorical\"\n",
        "            continue\n",
        "\n",
        "        if (\n",
        "            pd.api.types.is_object_dtype(s)\n",
        "            or isinstance(getattr(s, \"dtype\", None), pd.CategoricalDtype)\n",
        "            or pd.api.types.is_bool_dtype(s)\n",
        "        ):\n",
        "            schema[col] = \"categorical\"\n",
        "        elif pd.api.types.is_integer_dtype(s) and int(s.nunique(dropna=True)) <= 20:\n",
        "            schema[col] = \"categorical\"\n",
        "        else:\n",
        "            schema[col] = \"continuous\"\n",
        "    return schema\n",
        "\n",
        "def encode_dataset_with_schema(\n",
        "    df: pd.DataFrame,\n",
        "    schema: Dict[str, str],\n",
        "    max_categorical_classes: int,\n",
        "):\n",
        "    encoded = pd.DataFrame(index=df.index)\n",
        "    metadata_rows = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        kind = schema[col]\n",
        "        s = df[col]\n",
        "        raw_unique = int(pd.Series(s).nunique(dropna=True))\n",
        "\n",
        "        if kind == \"categorical\":\n",
        "            s_obj = pd.Series(s, copy=False)\n",
        "            s_obj = s_obj.where(s_obj.notna(), \"__MISSING__\").astype(\"string\")\n",
        "\n",
        "            counts = s_obj.value_counts(dropna=False)\n",
        "            if counts.shape[0] > max_categorical_classes:\n",
        "                keep_n = max(1, max_categorical_classes - 1)\n",
        "                keep_values = set(counts.index[:keep_n].tolist())\n",
        "                s_obj = s_obj.where(s_obj.isin(keep_values), \"__OTHER__\")\n",
        "\n",
        "            cat = pd.Categorical(s_obj.astype(str))\n",
        "            codes = cat.codes.astype(np.int64)\n",
        "            cardinality = int(len(cat.categories))\n",
        "\n",
        "            encoded[col] = codes.astype(np.float32)\n",
        "            metadata_rows.append(\n",
        "                {\n",
        "                    \"feature\": col,\n",
        "                    \"feature_type\": \"categorical\",\n",
        "                    \"raw_unique_values\": raw_unique,\n",
        "                    \"cardinality\": cardinality,\n",
        "                }\n",
        "            )\n",
        "        else:\n",
        "            s_num = pd.to_numeric(s, errors=\"coerce\")\n",
        "            fill_value = float(s_num.median()) if s_num.notna().any() else 0.0\n",
        "            s_num = s_num.fillna(fill_value).astype(np.float32)\n",
        "\n",
        "            encoded[col] = s_num\n",
        "            metadata_rows.append(\n",
        "                {\n",
        "                    \"feature\": col,\n",
        "                    \"feature_type\": \"continuous\",\n",
        "                    \"raw_unique_values\": raw_unique,\n",
        "                    \"cardinality\": 1,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    feature_metadata = pd.DataFrame(metadata_rows)\n",
        "    feature_is_categorical = (feature_metadata[\"feature_type\"].to_numpy() == \"categorical\")\n",
        "    feature_cardinalities = feature_metadata[\"cardinality\"].to_numpy(dtype=np.int64)\n",
        "\n",
        "    X_np = encoded.to_numpy(dtype=np.float32)\n",
        "    return X_np, feature_is_categorical, feature_cardinalities, feature_metadata\n",
        "\n",
        "\n",
        "def drop_high_cardinality_categorical_features(\n",
        "    df: pd.DataFrame,\n",
        "    schema: Dict[str, str],\n",
        "    max_allowed_cardinality: int = 10,\n",
        "):\n",
        "    drop_cols = []\n",
        "    for col in df.columns:\n",
        "        if schema.get(col) != \"categorical\":\n",
        "            continue\n",
        "        n_unique = int(pd.Series(df[col]).nunique(dropna=True))\n",
        "        if n_unique > max_allowed_cardinality:\n",
        "            drop_cols.append(col)\n",
        "\n",
        "    if len(drop_cols) > 0:\n",
        "        df = df.drop(columns=drop_cols)\n",
        "\n",
        "    schema = {col: schema[col] for col in df.columns if col in schema}\n",
        "    return df, schema, drop_cols\n",
        "\n",
        "\n",
        "def prepare_dataset(record: Dict, max_categorical_classes: int):\n",
        "    X_raw = record[\"X\"].reset_index(drop=True)\n",
        "    y_raw = pd.Series(record[\"y\"]).reset_index(drop=True)\n",
        "\n",
        "    valid = y_raw.notna()\n",
        "    X_raw = X_raw.loc[valid].reset_index(drop=True)\n",
        "    y_raw = y_raw.loc[valid].reset_index(drop=True)\n",
        "\n",
        "    if y_raw.nunique(dropna=True) != 2:\n",
        "        raise ValueError(f\"Dataset '{record['name']}' is not binary after cleaning.\")\n",
        "\n",
        "    schema = infer_feature_schema(X_raw, schema_hint=record.get(\"schema_hint\"))\n",
        "    X_filtered, schema, dropped_cols = drop_high_cardinality_categorical_features(\n",
        "        X_raw,\n",
        "        schema,\n",
        "        max_allowed_cardinality=10,\n",
        "    )\n",
        "    if X_filtered.shape[1] == 0:\n",
        "        raise ValueError(\n",
        "            f\"Dataset '{record['name']}' has no features after removing categorical columns with >10 classes.\"\n",
        "        )\n",
        "\n",
        "    X_np, feature_is_cat, feature_card, feature_meta = encode_dataset_with_schema(\n",
        "        X_filtered,\n",
        "        schema,\n",
        "        max_categorical_classes=max_categorical_classes,\n",
        "    )\n",
        "    if len(dropped_cols) > 0:\n",
        "        print(f\"[info] {record['name']}: dropped high-cardinality categorical columns: {sorted(dropped_cols)}\")\n",
        "\n",
        "    return {\n",
        "        \"name\": record[\"name\"],\n",
        "        \"source\": record[\"source\"],\n",
        "        \"X\": X_np,\n",
        "        \"y\": y_raw.to_numpy(),\n",
        "        \"feature_is_categorical\": feature_is_cat,\n",
        "        \"feature_cardinalities\": feature_card,\n",
        "        \"feature_metadata\": feature_meta,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "173ade27",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_pu_task(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    rng: np.random.Generator,\n",
        "    max_positive_size: int,\n",
        "    unlabeled_labeled_positive_ratio: tuple[int, int],\n",
        "    outlier_rate: float,\n",
        "):\n",
        "    labels = np.unique(y)\n",
        "    if labels.shape[0] != 2:\n",
        "        return None\n",
        "\n",
        "    positive_label = rng.choice(labels)\n",
        "    pos_idx = np.where(y == positive_label)[0]\n",
        "    neg_idx = np.where(y != positive_label)[0]\n",
        "\n",
        "    if len(pos_idx) < 2 or len(neg_idx) < 1:\n",
        "        return None\n",
        "\n",
        "    selected_pos_n = int(min(max_positive_size, len(pos_idx)))\n",
        "    selected_pos_idx = rng.choice(pos_idx, size=selected_pos_n, replace=False)\n",
        "\n",
        "    u_ratio, l_ratio = unlabeled_labeled_positive_ratio\n",
        "    if u_ratio < 0 or l_ratio <= 0 or (u_ratio + l_ratio) <= 0:\n",
        "        raise ValueError(\"UNLABELED_LABELED_POSITIVE_RATIO must be (u, l) with u>=0, l>0.\")\n",
        "\n",
        "    unlabeled_pos_n = int(round(selected_pos_n * (float(u_ratio) / float(u_ratio + l_ratio))))\n",
        "    unlabeled_pos_n = int(np.clip(unlabeled_pos_n, 1, selected_pos_n - 1))\n",
        "    labeled_pos_n = selected_pos_n - unlabeled_pos_n\n",
        "    if labeled_pos_n <= 0 or unlabeled_pos_n <= 0:\n",
        "        return None\n",
        "\n",
        "    labeled_pos_idx = rng.choice(selected_pos_idx, size=labeled_pos_n, replace=False)\n",
        "    unlabeled_pos_idx = np.setdiff1d(selected_pos_idx, labeled_pos_idx, assume_unique=False)\n",
        "\n",
        "    neg_needed = int(round(unlabeled_pos_n * outlier_rate / max(1e-8, 1.0 - outlier_rate)))\n",
        "    if outlier_rate > 0.0 and unlabeled_pos_n > 0:\n",
        "        neg_needed = max(1, neg_needed)\n",
        "    neg_needed = min(neg_needed, len(neg_idx))\n",
        "    if neg_needed <= 0:\n",
        "        return None\n",
        "\n",
        "    unlabeled_neg_idx = rng.choice(neg_idx, size=neg_needed, replace=False)\n",
        "\n",
        "    unlabeled_idx = np.concatenate([unlabeled_pos_idx, unlabeled_neg_idx])\n",
        "    unlabeled_y = np.concatenate(\n",
        "        [\n",
        "            np.zeros(unlabeled_pos_idx.shape[0], dtype=np.int64),  # inlier\n",
        "            np.ones(unlabeled_neg_idx.shape[0], dtype=np.int64),   # outlier\n",
        "        ]\n",
        "    )\n",
        "    perm = rng.permutation(unlabeled_idx.shape[0])\n",
        "    unlabeled_idx = unlabeled_idx[perm]\n",
        "    unlabeled_y = unlabeled_y[perm]\n",
        "\n",
        "    labeled_perm = rng.permutation(labeled_pos_idx.shape[0])\n",
        "    labeled_pos_idx = labeled_pos_idx[labeled_perm]\n",
        "\n",
        "    X_task = np.concatenate([X[labeled_pos_idx], X[unlabeled_idx]], axis=0).astype(np.float32)\n",
        "    y_train = np.zeros(labeled_pos_idx.shape[0], dtype=np.float32)\n",
        "\n",
        "    return {\n",
        "        \"X\": X_task,\n",
        "        \"y_train\": y_train,\n",
        "        \"y_test\": unlabeled_y,\n",
        "        \"train_size\": int(labeled_pos_idx.shape[0]),\n",
        "        \"num_unlabeled_inliers\": int(unlabeled_pos_idx.shape[0]),\n",
        "        \"num_unlabeled_outliers\": int(unlabeled_neg_idx.shape[0]),\n",
        "        \"positive_label\": str(positive_label),\n",
        "    }\n",
        "\n",
        "\n",
        "def fpr_at_fixed_tpr(y_true: np.ndarray, outlier_score: np.ndarray, target_tpr: float = 0.95) -> float:\n",
        "    if np.unique(y_true).shape[0] < 2:\n",
        "        return float(\"nan\")\n",
        "    fpr, tpr, _ = roc_curve(y_true, outlier_score)\n",
        "    valid = np.where(tpr >= target_tpr)[0]\n",
        "    if valid.size == 0:\n",
        "        return 1.0\n",
        "    return float(np.min(fpr[valid]))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_single_pu_task(\n",
        "    model,\n",
        "    task: Dict,\n",
        "    feature_is_categorical: np.ndarray,\n",
        "    feature_cardinalities: np.ndarray,\n",
        "    device: str,\n",
        "    supports_categorical: bool,\n",
        ") -> Dict[str, float]:\n",
        "    x = torch.from_numpy(task[\"X\"]).unsqueeze(0).to(device=device, dtype=torch.float32)\n",
        "    y_train = torch.from_numpy(task[\"y_train\"]).unsqueeze(0).to(device=device, dtype=torch.float32)\n",
        "\n",
        "    if supports_categorical:\n",
        "        feature_is_cat_t = torch.from_numpy(feature_is_categorical).unsqueeze(0).to(device=device, dtype=torch.bool)\n",
        "        feature_card_t = torch.from_numpy(feature_cardinalities).unsqueeze(0).to(device=device, dtype=torch.long)\n",
        "        logits = model(\n",
        "            (x, y_train),\n",
        "            train_test_split_index=task[\"train_size\"],\n",
        "            feature_is_categorical=feature_is_cat_t,\n",
        "            feature_cardinalities=feature_card_t,\n",
        "        ).squeeze(0)\n",
        "    else:\n",
        "        logits = model(\n",
        "            (x, y_train),\n",
        "            train_test_split_index=task[\"train_size\"],\n",
        "        ).squeeze(0)\n",
        "\n",
        "    logits_np = logits.detach().cpu().numpy()\n",
        "    y_true = task[\"y_test\"].astype(np.int64)\n",
        "    y_pred = np.argmax(logits_np, axis=1)\n",
        "\n",
        "    outlier_score = logits_np[:, 1]\n",
        "\n",
        "    binary_ready = np.unique(y_true).shape[0] == 2\n",
        "    outlier_mean = float(np.mean(outlier_score[y_true == 1])) if np.any(y_true == 1) else float(\"nan\")\n",
        "    inlier_mean = float(np.mean(outlier_score[y_true == 0])) if np.any(y_true == 0) else float(\"nan\")\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
        "        \"balanced_accuracy\": float(balanced_accuracy_score(y_true, y_pred)),\n",
        "        \"roc_auc\": float(roc_auc_score(y_true, outlier_score)) if binary_ready else float(\"nan\"),\n",
        "        \"average_precision\": float(average_precision_score(y_true, outlier_score)) if binary_ready else float(\"nan\"),\n",
        "        \"fpr_at_tpr_0_80\": float(fpr_at_fixed_tpr(y_true, outlier_score, target_tpr=0.80)),\n",
        "        \"fpr_at_tpr_0_90\": float(fpr_at_fixed_tpr(y_true, outlier_score, target_tpr=0.90)),\n",
        "        \"fpr_at_tpr_0_95\": float(fpr_at_fixed_tpr(y_true, outlier_score, target_tpr=0.95)),\n",
        "        \"outlier_score_gap\": float(outlier_mean - inlier_mean)\n",
        "        if (not np.isnan(outlier_mean) and not np.isnan(inlier_mean))\n",
        "        else float(\"nan\"),\n",
        "    }\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "290a6916",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] uci_adult_mixed: dropped high-cardinality categorical columns: ['education', 'native_country', 'occupation']\n",
            "[info] uci_mushroom_categorical: dropped high-cardinality categorical columns: ['gill_color']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>source</th>\n",
              "      <th>rows</th>\n",
              "      <th>features</th>\n",
              "      <th>continuous_features</th>\n",
              "      <th>categorical_features</th>\n",
              "      <th>max_categorical_cardinality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uci_wdbc_continuous</td>\n",
              "      <td>uci:wdbc</td>\n",
              "      <td>569</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>uci_adult_mixed</td>\n",
              "      <td>uci:adult</td>\n",
              "      <td>30162</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uci_spambase_continuous</td>\n",
              "      <td>uci:spambase</td>\n",
              "      <td>4601</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uci_mushroom_categorical</td>\n",
              "      <td>uci:mushroom</td>\n",
              "      <td>8124</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uci_magic_gamma_continuous</td>\n",
              "      <td>uci:magic-gamma-telescope</td>\n",
              "      <td>19020</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>uci_car_evaluation_categorical</td>\n",
              "      <td>uci:car-evaluation</td>\n",
              "      <td>1728</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>uci_banknote_authentication_continuous</td>\n",
              "      <td>uci:banknote-authentication</td>\n",
              "      <td>1372</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>uci_rice_cammeo_osmancik_continuous</td>\n",
              "      <td>uci:rice-cammeo-and-osmancik</td>\n",
              "      <td>3810</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>uci_default_credit_card_clients_continuous</td>\n",
              "      <td>uci:default-of-credit-card-clients</td>\n",
              "      <td>30000</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>uci_abalone_binary_rings_cutoff</td>\n",
              "      <td>uci:abalone</td>\n",
              "      <td>4177</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>uci_letter_recognition_C_vs_U</td>\n",
              "      <td>uci:letter-recognition</td>\n",
              "      <td>1549</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       dataset  \\\n",
              "0                          uci_wdbc_continuous   \n",
              "1                              uci_adult_mixed   \n",
              "2                      uci_spambase_continuous   \n",
              "3                     uci_mushroom_categorical   \n",
              "4                   uci_magic_gamma_continuous   \n",
              "5               uci_car_evaluation_categorical   \n",
              "6       uci_banknote_authentication_continuous   \n",
              "7          uci_rice_cammeo_osmancik_continuous   \n",
              "8   uci_default_credit_card_clients_continuous   \n",
              "9              uci_abalone_binary_rings_cutoff   \n",
              "10               uci_letter_recognition_C_vs_U   \n",
              "\n",
              "                                source   rows  features  continuous_features  \\\n",
              "0                             uci:wdbc    569        30                   30   \n",
              "1                            uci:adult  30162        11                    6   \n",
              "2                         uci:spambase   4601        57                   57   \n",
              "3                         uci:mushroom   8124        20                    0   \n",
              "4            uci:magic-gamma-telescope  19020        10                   10   \n",
              "5                   uci:car-evaluation   1728         6                    0   \n",
              "6          uci:banknote-authentication   1372         4                    4   \n",
              "7         uci:rice-cammeo-and-osmancik   3810         7                    7   \n",
              "8   uci:default-of-credit-card-clients  30000        23                   23   \n",
              "9                          uci:abalone   4177         8                    8   \n",
              "10              uci:letter-recognition   1549        16                   16   \n",
              "\n",
              "    categorical_features  max_categorical_cardinality  \n",
              "0                      0                            1  \n",
              "1                      5                            7  \n",
              "2                      0                            1  \n",
              "3                     20                           10  \n",
              "4                      0                            1  \n",
              "5                      6                            4  \n",
              "6                      0                            1  \n",
              "7                      0                            1  \n",
              "8                      0                            1  \n",
              "9                      0                            1  \n",
              "10                     0                            1  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prepared_datasets = [prepare_dataset(d, max_categorical_classes=MAX_CATEGORICAL_CLASSES) for d in benchmark_datasets]\n",
        "\n",
        "profile_rows = []\n",
        "for d in prepared_datasets:\n",
        "    feature_meta = d[\"feature_metadata\"]\n",
        "    num_cat = int((feature_meta[\"feature_type\"] == \"categorical\").sum())\n",
        "    num_cont = int((feature_meta[\"feature_type\"] == \"continuous\").sum())\n",
        "    max_card = int(feature_meta.loc[feature_meta[\"feature_type\"] == \"categorical\", \"cardinality\"].max()) if num_cat > 0 else 1\n",
        "    profile_rows.append(\n",
        "        {\n",
        "            \"dataset\": d[\"name\"],\n",
        "            \"source\": d[\"source\"],\n",
        "            \"rows\": int(d[\"X\"].shape[0]),\n",
        "            \"features\": int(d[\"X\"].shape[1]),\n",
        "            \"continuous_features\": num_cont,\n",
        "            \"categorical_features\": num_cat,\n",
        "            \"max_categorical_cardinality\": max_card,\n",
        "        }\n",
        "    )\n",
        "\n",
        "profile_df = pd.DataFrame(profile_rows)\n",
        "profile_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "dc70078f",
      "metadata": {},
      "outputs": [],
      "source": [
        "rng_master = np.random.default_rng(GLOBAL_SEED)\n",
        "\n",
        "replicate_frames = []\n",
        "\n",
        "for dataset_idx, dataset in enumerate(prepared_datasets):\n",
        "    ds_seed = int(rng_master.integers(0, 2**31 - 1))\n",
        "    ds_rng = np.random.default_rng(ds_seed)\n",
        "\n",
        "    rows = []\n",
        "    attempts = 0\n",
        "    collected_replicates = 0\n",
        "\n",
        "    while collected_replicates < N_REPLICATES and attempts < MAX_ATTEMPTS_PER_DATASET:\n",
        "        attempts += 1\n",
        "        task = build_pu_task(\n",
        "            X=dataset[\"X\"],\n",
        "            y=dataset[\"y\"],\n",
        "            rng=ds_rng,\n",
        "            max_positive_size=MAX_POSITIVE_SIZE,\n",
        "            unlabeled_labeled_positive_ratio=UNLABELED_LABELED_POSITIVE_RATIO,\n",
        "            outlier_rate=OUTLIER_RATE,\n",
        "        )\n",
        "        if task is None:\n",
        "            continue\n",
        "\n",
        "        unlabeled_total = int(task[\"num_unlabeled_inliers\"] + task[\"num_unlabeled_outliers\"])\n",
        "        real_outlier_proportion = (\n",
        "            float(task[\"num_unlabeled_outliers\"]) / float(unlabeled_total) if unlabeled_total > 0 else float(\"nan\")\n",
        "        )\n",
        "        real_unlabeled_positive_to_labeled_positive_ratio = (\n",
        "            float(task[\"num_unlabeled_inliers\"]) / float(task[\"train_size\"]) if int(task[\"train_size\"]) > 0 else float(\"nan\")\n",
        "        )\n",
        "        real_positive_only_sample_size = int(task[\"train_size\"] + task[\"num_unlabeled_inliers\"])\n",
        "\n",
        "        for model_spec in MODEL_SPECS:\n",
        "            metric = evaluate_single_pu_task(\n",
        "                model=model_spec[\"model\"],\n",
        "                task=task,\n",
        "                feature_is_categorical=dataset[\"feature_is_categorical\"],\n",
        "                feature_cardinalities=dataset[\"feature_cardinalities\"],\n",
        "                device=DEVICE,\n",
        "                supports_categorical=bool(model_spec[\"supports_categorical\"]),\n",
        "            )\n",
        "            metric.update(\n",
        "                {\n",
        "                    \"model_name\": model_spec[\"model_name\"],\n",
        "                    \"dataset\": dataset[\"name\"],\n",
        "                    \"source\": dataset[\"source\"],\n",
        "                    \"replicate\": collected_replicates + 1,\n",
        "                    \"attempt\": attempts,\n",
        "                    \"positive_label\": task[\"positive_label\"],\n",
        "                    \"labeled_positive_size\": int(task[\"train_size\"]),\n",
        "                    \"real_labeled_positive_size\": int(task[\"train_size\"]),\n",
        "                    \"real_positive_only_sample_size\": real_positive_only_sample_size,\n",
        "                    \"unlabeled_inlier_size\": int(task[\"num_unlabeled_inliers\"]),\n",
        "                    \"unlabeled_outlier_size\": int(task[\"num_unlabeled_outliers\"]),\n",
        "                    \"real_outlier_proportion\": real_outlier_proportion,\n",
        "                    \"real_unlabeled_positive_to_labeled_positive_ratio\": real_unlabeled_positive_to_labeled_positive_ratio,\n",
        "                }\n",
        "            )\n",
        "            rows.append(metric)\n",
        "\n",
        "        collected_replicates += 1\n",
        "\n",
        "    if collected_replicates < N_REPLICATES:\n",
        "        print(\n",
        "            f\"[warn] dataset={dataset['name']} collected {collected_replicates} replicates \"\n",
        "            f\"within {MAX_ATTEMPTS_PER_DATASET} attempts.\"\n",
        "        )\n",
        "\n",
        "    rep_df = pd.DataFrame(rows)\n",
        "    replicate_frames.append(rep_df)\n",
        "\n",
        "replicate_results_df = pd.concat(replicate_frames, ignore_index=True) if len(replicate_frames) > 0 else pd.DataFrame()\n",
        "\n",
        "metric_columns = [\n",
        "    \"accuracy\",\n",
        "    \"balanced_accuracy\",\n",
        "    \"roc_auc\",\n",
        "    \"average_precision\",\n",
        "    \"fpr_at_tpr_0_80\",\n",
        "    \"fpr_at_tpr_0_90\",\n",
        "    \"fpr_at_tpr_0_95\",\n",
        "    \"outlier_score_gap\",\n",
        "]\n",
        "\n",
        "if replicate_results_df.empty:\n",
        "    metrics_by_model_df = pd.DataFrame(\n",
        "        columns=[\"dataset\", \"source\", \"model_name\", \"replicates\"] + metric_columns\n",
        "    )\n",
        "    metrics_latest_df = pd.DataFrame(columns=[\"dataset\", \"source\", \"replicates\"] + metric_columns)\n",
        "    metrics_legacy_df = pd.DataFrame(columns=[\"dataset\", \"source\", \"replicates\"] + metric_columns)\n",
        "\n",
        "    metrics_summary_df = pd.DataFrame(\n",
        "        columns=[\"dataset\", \"source\", \"replicates_latest\", \"replicates_legacy\"]\n",
        "        + [\n",
        "            col_name\n",
        "            for metric in metric_columns\n",
        "            for col_name in (\n",
        "                f\"{metric}_latest\",\n",
        "                f\"{metric}_legacy\",\n",
        "                f\"{metric}_delta_latest_minus_legacy\",\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    composition_summary_df = pd.DataFrame(\n",
        "        columns=[\n",
        "            \"dataset\",\n",
        "            \"source\",\n",
        "            \"replicates\",\n",
        "            \"true_positive_only_sample_size\",\n",
        "            \"true_unlabeled_to_labeled_positive_ratio\",\n",
        "            \"true_outlier_rate\",\n",
        "        ]\n",
        "    )\n",
        "else:\n",
        "    metrics_by_model_df = (\n",
        "        replicate_results_df.groupby([\"dataset\", \"source\", \"model_name\"], as_index=False)\n",
        "        .agg(\n",
        "            replicates=(\"replicate\", \"count\"),\n",
        "            accuracy=(\"accuracy\", \"mean\"),\n",
        "            balanced_accuracy=(\"balanced_accuracy\", \"mean\"),\n",
        "            roc_auc=(\"roc_auc\", \"mean\"),\n",
        "            average_precision=(\"average_precision\", \"mean\"),\n",
        "            fpr_at_tpr_0_80=(\"fpr_at_tpr_0_80\", \"mean\"),\n",
        "            fpr_at_tpr_0_90=(\"fpr_at_tpr_0_90\", \"mean\"),\n",
        "            fpr_at_tpr_0_95=(\"fpr_at_tpr_0_95\", \"mean\"),\n",
        "            outlier_score_gap=(\"outlier_score_gap\", \"mean\"),\n",
        "        )\n",
        "        .sort_values([\"dataset\", \"model_name\"])\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    metrics_latest_df = (\n",
        "        metrics_by_model_df[metrics_by_model_df[\"model_name\"] == \"latest\"]\n",
        "        .drop(columns=[\"model_name\"])\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    metrics_legacy_df = (\n",
        "        metrics_by_model_df[metrics_by_model_df[\"model_name\"] == \"legacy\"]\n",
        "        .drop(columns=[\"model_name\"])\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    latest_for_merge = metrics_latest_df.rename(\n",
        "        columns={\"replicates\": \"replicates_latest\", **{metric: f\"{metric}_latest\" for metric in metric_columns}}\n",
        "    )\n",
        "    legacy_for_merge = metrics_legacy_df.rename(\n",
        "        columns={\"replicates\": \"replicates_legacy\", **{metric: f\"{metric}_legacy\" for metric in metric_columns}}\n",
        "    )\n",
        "\n",
        "    metrics_summary_df = (\n",
        "        latest_for_merge.merge(legacy_for_merge, on=[\"dataset\", \"source\"], how=\"outer\")\n",
        "        .sort_values(\"dataset\")\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    for metric in metric_columns:\n",
        "        latest_col = f\"{metric}_latest\"\n",
        "        legacy_col = f\"{metric}_legacy\"\n",
        "        delta_col = f\"{metric}_delta_latest_minus_legacy\"\n",
        "        if latest_col in metrics_summary_df.columns and legacy_col in metrics_summary_df.columns:\n",
        "            metrics_summary_df[delta_col] = metrics_summary_df[latest_col] - metrics_summary_df[legacy_col]\n",
        "        else:\n",
        "            metrics_summary_df[delta_col] = float(\"nan\")\n",
        "\n",
        "    # True PU composition is task-defined (independent of model); compute once from latest rows.\n",
        "    composition_source_df = replicate_results_df[replicate_results_df[\"model_name\"] == \"latest\"]\n",
        "    composition_summary_df = (\n",
        "        composition_source_df.groupby([\"dataset\", \"source\"], as_index=False)\n",
        "        .agg(\n",
        "            replicates=(\"replicate\", \"count\"),\n",
        "            true_positive_only_sample_size=(\"real_positive_only_sample_size\", \"mean\"),\n",
        "            true_unlabeled_to_labeled_positive_ratio=(\"real_unlabeled_positive_to_labeled_positive_ratio\", \"mean\"),\n",
        "            true_outlier_rate=(\"real_outlier_proportion\", \"mean\"),\n",
        "        )\n",
        "        .sort_values(\"dataset\")\n",
        "        .reset_index(drop=True)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6b5b24b0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance metrics over replicates: latest model\n",
            "outlier_score_gap = mean(outlier score for true outliers) - mean(outlier score for true inliers)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>source</th>\n",
              "      <th>replicates</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>average_precision</th>\n",
              "      <th>fpr_at_tpr_0_80</th>\n",
              "      <th>fpr_at_tpr_0_90</th>\n",
              "      <th>fpr_at_tpr_0_95</th>\n",
              "      <th>outlier_score_gap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uci_abalone_binary_rings_cutoff</td>\n",
              "      <td>uci:abalone</td>\n",
              "      <td>10</td>\n",
              "      <td>0.863043</td>\n",
              "      <td>0.732833</td>\n",
              "      <td>0.852922</td>\n",
              "      <td>0.572570</td>\n",
              "      <td>0.259500</td>\n",
              "      <td>0.433833</td>\n",
              "      <td>0.582000</td>\n",
              "      <td>0.980327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>uci_adult_mixed</td>\n",
              "      <td>uci:adult</td>\n",
              "      <td>10</td>\n",
              "      <td>0.131014</td>\n",
              "      <td>0.499861</td>\n",
              "      <td>0.707013</td>\n",
              "      <td>0.326188</td>\n",
              "      <td>0.485500</td>\n",
              "      <td>0.711333</td>\n",
              "      <td>0.870167</td>\n",
              "      <td>0.376068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uci_banknote_authentication_continuous</td>\n",
              "      <td>uci:banknote-authentication</td>\n",
              "      <td>10</td>\n",
              "      <td>0.976869</td>\n",
              "      <td>0.986702</td>\n",
              "      <td>0.999797</td>\n",
              "      <td>0.998902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.650060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uci_car_evaluation_categorical</td>\n",
              "      <td>uci:car-evaluation</td>\n",
              "      <td>10</td>\n",
              "      <td>0.351194</td>\n",
              "      <td>0.550510</td>\n",
              "      <td>0.839790</td>\n",
              "      <td>0.552646</td>\n",
              "      <td>0.306612</td>\n",
              "      <td>0.433485</td>\n",
              "      <td>0.583785</td>\n",
              "      <td>0.750079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uci_default_credit_card_clients_continuous</td>\n",
              "      <td>uci:default-of-credit-card-clients</td>\n",
              "      <td>10</td>\n",
              "      <td>0.857681</td>\n",
              "      <td>0.521972</td>\n",
              "      <td>0.628150</td>\n",
              "      <td>0.236282</td>\n",
              "      <td>0.675500</td>\n",
              "      <td>0.832833</td>\n",
              "      <td>0.914167</td>\n",
              "      <td>0.146138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>uci_letter_recognition_C_vs_U</td>\n",
              "      <td>uci:letter-recognition</td>\n",
              "      <td>10</td>\n",
              "      <td>0.970276</td>\n",
              "      <td>0.956098</td>\n",
              "      <td>0.994319</td>\n",
              "      <td>0.972273</td>\n",
              "      <td>0.001610</td>\n",
              "      <td>0.010157</td>\n",
              "      <td>0.034492</td>\n",
              "      <td>3.128218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>uci_magic_gamma_continuous</td>\n",
              "      <td>uci:magic-gamma-telescope</td>\n",
              "      <td>10</td>\n",
              "      <td>0.882754</td>\n",
              "      <td>0.632250</td>\n",
              "      <td>0.817622</td>\n",
              "      <td>0.499203</td>\n",
              "      <td>0.338000</td>\n",
              "      <td>0.487667</td>\n",
              "      <td>0.600833</td>\n",
              "      <td>0.775427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>uci_mushroom_categorical</td>\n",
              "      <td>uci:mushroom</td>\n",
              "      <td>10</td>\n",
              "      <td>0.132029</td>\n",
              "      <td>0.500444</td>\n",
              "      <td>0.924930</td>\n",
              "      <td>0.764888</td>\n",
              "      <td>0.092000</td>\n",
              "      <td>0.240667</td>\n",
              "      <td>0.377833</td>\n",
              "      <td>1.284515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>uci_rice_cammeo_osmancik_continuous</td>\n",
              "      <td>uci:rice-cammeo-and-osmancik</td>\n",
              "      <td>10</td>\n",
              "      <td>0.942754</td>\n",
              "      <td>0.864139</td>\n",
              "      <td>0.962948</td>\n",
              "      <td>0.863908</td>\n",
              "      <td>0.036333</td>\n",
              "      <td>0.088000</td>\n",
              "      <td>0.182833</td>\n",
              "      <td>4.952948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>uci_spambase_continuous</td>\n",
              "      <td>uci:spambase</td>\n",
              "      <td>10</td>\n",
              "      <td>0.879420</td>\n",
              "      <td>0.777194</td>\n",
              "      <td>0.887322</td>\n",
              "      <td>0.664657</td>\n",
              "      <td>0.173833</td>\n",
              "      <td>0.356833</td>\n",
              "      <td>0.556667</td>\n",
              "      <td>0.886307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>uci_wdbc_continuous</td>\n",
              "      <td>uci:wdbc</td>\n",
              "      <td>10</td>\n",
              "      <td>0.843255</td>\n",
              "      <td>0.884934</td>\n",
              "      <td>0.949853</td>\n",
              "      <td>0.837607</td>\n",
              "      <td>0.061148</td>\n",
              "      <td>0.110811</td>\n",
              "      <td>0.183584</td>\n",
              "      <td>3.209529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       dataset  \\\n",
              "0              uci_abalone_binary_rings_cutoff   \n",
              "1                              uci_adult_mixed   \n",
              "2       uci_banknote_authentication_continuous   \n",
              "3               uci_car_evaluation_categorical   \n",
              "4   uci_default_credit_card_clients_continuous   \n",
              "5                uci_letter_recognition_C_vs_U   \n",
              "6                   uci_magic_gamma_continuous   \n",
              "7                     uci_mushroom_categorical   \n",
              "8          uci_rice_cammeo_osmancik_continuous   \n",
              "9                      uci_spambase_continuous   \n",
              "10                         uci_wdbc_continuous   \n",
              "\n",
              "                                source  replicates  accuracy  \\\n",
              "0                          uci:abalone          10  0.863043   \n",
              "1                            uci:adult          10  0.131014   \n",
              "2          uci:banknote-authentication          10  0.976869   \n",
              "3                   uci:car-evaluation          10  0.351194   \n",
              "4   uci:default-of-credit-card-clients          10  0.857681   \n",
              "5               uci:letter-recognition          10  0.970276   \n",
              "6            uci:magic-gamma-telescope          10  0.882754   \n",
              "7                         uci:mushroom          10  0.132029   \n",
              "8         uci:rice-cammeo-and-osmancik          10  0.942754   \n",
              "9                         uci:spambase          10  0.879420   \n",
              "10                            uci:wdbc          10  0.843255   \n",
              "\n",
              "    balanced_accuracy   roc_auc  average_precision  fpr_at_tpr_0_80  \\\n",
              "0            0.732833  0.852922           0.572570         0.259500   \n",
              "1            0.499861  0.707013           0.326188         0.485500   \n",
              "2            0.986702  0.999797           0.998902         0.000000   \n",
              "3            0.550510  0.839790           0.552646         0.306612   \n",
              "4            0.521972  0.628150           0.236282         0.675500   \n",
              "5            0.956098  0.994319           0.972273         0.001610   \n",
              "6            0.632250  0.817622           0.499203         0.338000   \n",
              "7            0.500444  0.924930           0.764888         0.092000   \n",
              "8            0.864139  0.962948           0.863908         0.036333   \n",
              "9            0.777194  0.887322           0.664657         0.173833   \n",
              "10           0.884934  0.949853           0.837607         0.061148   \n",
              "\n",
              "    fpr_at_tpr_0_90  fpr_at_tpr_0_95  outlier_score_gap  \n",
              "0          0.433833         0.582000           0.980327  \n",
              "1          0.711333         0.870167           0.376068  \n",
              "2          0.000000         0.000000           4.650060  \n",
              "3          0.433485         0.583785           0.750079  \n",
              "4          0.832833         0.914167           0.146138  \n",
              "5          0.010157         0.034492           3.128218  \n",
              "6          0.487667         0.600833           0.775427  \n",
              "7          0.240667         0.377833           1.284515  \n",
              "8          0.088000         0.182833           4.952948  \n",
              "9          0.356833         0.556667           0.886307  \n",
              "10         0.110811         0.183584           3.209529  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Performance metrics over replicates: latest model\")\n",
        "print(\"outlier_score_gap = mean(outlier score for true outliers) - mean(outlier score for true inliers)\")\n",
        "metrics_latest_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f9af922f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance metrics over replicates: legacy model\n",
            "outlier_score_gap = mean(outlier score for true outliers) - mean(outlier score for true inliers)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>source</th>\n",
              "      <th>replicates</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>average_precision</th>\n",
              "      <th>fpr_at_tpr_0_80</th>\n",
              "      <th>fpr_at_tpr_0_90</th>\n",
              "      <th>fpr_at_tpr_0_95</th>\n",
              "      <th>outlier_score_gap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uci_abalone_binary_rings_cutoff</td>\n",
              "      <td>uci:abalone</td>\n",
              "      <td>10</td>\n",
              "      <td>0.848841</td>\n",
              "      <td>0.743083</td>\n",
              "      <td>0.834152</td>\n",
              "      <td>0.542298</td>\n",
              "      <td>0.305000</td>\n",
              "      <td>0.464500</td>\n",
              "      <td>0.615500</td>\n",
              "      <td>0.643791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>uci_adult_mixed</td>\n",
              "      <td>uci:adult</td>\n",
              "      <td>10</td>\n",
              "      <td>0.849565</td>\n",
              "      <td>0.677389</td>\n",
              "      <td>0.759678</td>\n",
              "      <td>0.453299</td>\n",
              "      <td>0.456000</td>\n",
              "      <td>0.686333</td>\n",
              "      <td>0.828000</td>\n",
              "      <td>0.295297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uci_banknote_authentication_continuous</td>\n",
              "      <td>uci:banknote-authentication</td>\n",
              "      <td>10</td>\n",
              "      <td>0.958265</td>\n",
              "      <td>0.976007</td>\n",
              "      <td>0.999678</td>\n",
              "      <td>0.998091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000983</td>\n",
              "      <td>3.863725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uci_car_evaluation_categorical</td>\n",
              "      <td>uci:car-evaluation</td>\n",
              "      <td>10</td>\n",
              "      <td>0.674749</td>\n",
              "      <td>0.701178</td>\n",
              "      <td>0.855170</td>\n",
              "      <td>0.562884</td>\n",
              "      <td>0.281923</td>\n",
              "      <td>0.369346</td>\n",
              "      <td>0.492478</td>\n",
              "      <td>0.847423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uci_default_credit_card_clients_continuous</td>\n",
              "      <td>uci:default-of-credit-card-clients</td>\n",
              "      <td>10</td>\n",
              "      <td>0.856957</td>\n",
              "      <td>0.542806</td>\n",
              "      <td>0.615780</td>\n",
              "      <td>0.233514</td>\n",
              "      <td>0.719000</td>\n",
              "      <td>0.843500</td>\n",
              "      <td>0.919500</td>\n",
              "      <td>0.110759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>uci_letter_recognition_C_vs_U</td>\n",
              "      <td>uci:letter-recognition</td>\n",
              "      <td>10</td>\n",
              "      <td>0.959197</td>\n",
              "      <td>0.950668</td>\n",
              "      <td>0.993585</td>\n",
              "      <td>0.967343</td>\n",
              "      <td>0.003850</td>\n",
              "      <td>0.012174</td>\n",
              "      <td>0.041098</td>\n",
              "      <td>2.597320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>uci_magic_gamma_continuous</td>\n",
              "      <td>uci:magic-gamma-telescope</td>\n",
              "      <td>10</td>\n",
              "      <td>0.867826</td>\n",
              "      <td>0.662861</td>\n",
              "      <td>0.795263</td>\n",
              "      <td>0.475472</td>\n",
              "      <td>0.388667</td>\n",
              "      <td>0.549500</td>\n",
              "      <td>0.688333</td>\n",
              "      <td>0.406703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>uci_mushroom_categorical</td>\n",
              "      <td>uci:mushroom</td>\n",
              "      <td>10</td>\n",
              "      <td>0.950725</td>\n",
              "      <td>0.940500</td>\n",
              "      <td>0.982233</td>\n",
              "      <td>0.925381</td>\n",
              "      <td>0.007667</td>\n",
              "      <td>0.017667</td>\n",
              "      <td>0.097167</td>\n",
              "      <td>1.668629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>uci_rice_cammeo_osmancik_continuous</td>\n",
              "      <td>uci:rice-cammeo-and-osmancik</td>\n",
              "      <td>10</td>\n",
              "      <td>0.940725</td>\n",
              "      <td>0.879972</td>\n",
              "      <td>0.963887</td>\n",
              "      <td>0.864864</td>\n",
              "      <td>0.034000</td>\n",
              "      <td>0.093167</td>\n",
              "      <td>0.169000</td>\n",
              "      <td>3.923024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>uci_spambase_continuous</td>\n",
              "      <td>uci:spambase</td>\n",
              "      <td>10</td>\n",
              "      <td>0.891884</td>\n",
              "      <td>0.788139</td>\n",
              "      <td>0.872294</td>\n",
              "      <td>0.664551</td>\n",
              "      <td>0.204667</td>\n",
              "      <td>0.386333</td>\n",
              "      <td>0.636000</td>\n",
              "      <td>0.607235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>uci_wdbc_continuous</td>\n",
              "      <td>uci:wdbc</td>\n",
              "      <td>10</td>\n",
              "      <td>0.796359</td>\n",
              "      <td>0.860331</td>\n",
              "      <td>0.945447</td>\n",
              "      <td>0.821983</td>\n",
              "      <td>0.074727</td>\n",
              "      <td>0.131456</td>\n",
              "      <td>0.218908</td>\n",
              "      <td>2.269038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       dataset  \\\n",
              "0              uci_abalone_binary_rings_cutoff   \n",
              "1                              uci_adult_mixed   \n",
              "2       uci_banknote_authentication_continuous   \n",
              "3               uci_car_evaluation_categorical   \n",
              "4   uci_default_credit_card_clients_continuous   \n",
              "5                uci_letter_recognition_C_vs_U   \n",
              "6                   uci_magic_gamma_continuous   \n",
              "7                     uci_mushroom_categorical   \n",
              "8          uci_rice_cammeo_osmancik_continuous   \n",
              "9                      uci_spambase_continuous   \n",
              "10                         uci_wdbc_continuous   \n",
              "\n",
              "                                source  replicates  accuracy  \\\n",
              "0                          uci:abalone          10  0.848841   \n",
              "1                            uci:adult          10  0.849565   \n",
              "2          uci:banknote-authentication          10  0.958265   \n",
              "3                   uci:car-evaluation          10  0.674749   \n",
              "4   uci:default-of-credit-card-clients          10  0.856957   \n",
              "5               uci:letter-recognition          10  0.959197   \n",
              "6            uci:magic-gamma-telescope          10  0.867826   \n",
              "7                         uci:mushroom          10  0.950725   \n",
              "8         uci:rice-cammeo-and-osmancik          10  0.940725   \n",
              "9                         uci:spambase          10  0.891884   \n",
              "10                            uci:wdbc          10  0.796359   \n",
              "\n",
              "    balanced_accuracy   roc_auc  average_precision  fpr_at_tpr_0_80  \\\n",
              "0            0.743083  0.834152           0.542298         0.305000   \n",
              "1            0.677389  0.759678           0.453299         0.456000   \n",
              "2            0.976007  0.999678           0.998091         0.000000   \n",
              "3            0.701178  0.855170           0.562884         0.281923   \n",
              "4            0.542806  0.615780           0.233514         0.719000   \n",
              "5            0.950668  0.993585           0.967343         0.003850   \n",
              "6            0.662861  0.795263           0.475472         0.388667   \n",
              "7            0.940500  0.982233           0.925381         0.007667   \n",
              "8            0.879972  0.963887           0.864864         0.034000   \n",
              "9            0.788139  0.872294           0.664551         0.204667   \n",
              "10           0.860331  0.945447           0.821983         0.074727   \n",
              "\n",
              "    fpr_at_tpr_0_90  fpr_at_tpr_0_95  outlier_score_gap  \n",
              "0          0.464500         0.615500           0.643791  \n",
              "1          0.686333         0.828000           0.295297  \n",
              "2          0.000000         0.000983           3.863725  \n",
              "3          0.369346         0.492478           0.847423  \n",
              "4          0.843500         0.919500           0.110759  \n",
              "5          0.012174         0.041098           2.597320  \n",
              "6          0.549500         0.688333           0.406703  \n",
              "7          0.017667         0.097167           1.668629  \n",
              "8          0.093167         0.169000           3.923024  \n",
              "9          0.386333         0.636000           0.607235  \n",
              "10         0.131456         0.218908           2.269038  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Performance metrics over replicates: legacy model\")\n",
        "print(\"outlier_score_gap = mean(outlier score for true outliers) - mean(outlier score for true inliers)\")\n",
        "metrics_legacy_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e56cb6c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True PU composition over replicates (additional table):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>source</th>\n",
              "      <th>replicates</th>\n",
              "      <th>true_positive_only_sample_size</th>\n",
              "      <th>true_unlabeled_to_labeled_positive_ratio</th>\n",
              "      <th>true_outlier_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uci_abalone_binary_rings_cutoff</td>\n",
              "      <td>uci:abalone</td>\n",
              "      <td>10</td>\n",
              "      <td>900.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>uci_adult_mixed</td>\n",
              "      <td>uci:adult</td>\n",
              "      <td>10</td>\n",
              "      <td>900.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uci_banknote_authentication_continuous</td>\n",
              "      <td>uci:banknote-authentication</td>\n",
              "      <td>10</td>\n",
              "      <td>701.2</td>\n",
              "      <td>2.001970</td>\n",
              "      <td>0.130219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uci_car_evaluation_categorical</td>\n",
              "      <td>uci:car-evaluation</td>\n",
              "      <td>10</td>\n",
              "      <td>440.4</td>\n",
              "      <td>1.986667</td>\n",
              "      <td>0.128645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uci_default_credit_card_clients_continuous</td>\n",
              "      <td>uci:default-of-credit-card-clients</td>\n",
              "      <td>10</td>\n",
              "      <td>900.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>uci_letter_recognition_C_vs_U</td>\n",
              "      <td>uci:letter-recognition</td>\n",
              "      <td>10</td>\n",
              "      <td>759.1</td>\n",
              "      <td>2.002857</td>\n",
              "      <td>0.129608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>uci_magic_gamma_continuous</td>\n",
              "      <td>uci:magic-gamma-telescope</td>\n",
              "      <td>10</td>\n",
              "      <td>900.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>uci_mushroom_categorical</td>\n",
              "      <td>uci:mushroom</td>\n",
              "      <td>10</td>\n",
              "      <td>900.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>uci_rice_cammeo_osmancik_continuous</td>\n",
              "      <td>uci:rice-cammeo-and-osmancik</td>\n",
              "      <td>10</td>\n",
              "      <td>900.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>uci_spambase_continuous</td>\n",
              "      <td>uci:spambase</td>\n",
              "      <td>10</td>\n",
              "      <td>900.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>uci_wdbc_continuous</td>\n",
              "      <td>uci:wdbc</td>\n",
              "      <td>10</td>\n",
              "      <td>313.5</td>\n",
              "      <td>1.995775</td>\n",
              "      <td>0.130860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       dataset  \\\n",
              "0              uci_abalone_binary_rings_cutoff   \n",
              "1                              uci_adult_mixed   \n",
              "2       uci_banknote_authentication_continuous   \n",
              "3               uci_car_evaluation_categorical   \n",
              "4   uci_default_credit_card_clients_continuous   \n",
              "5                uci_letter_recognition_C_vs_U   \n",
              "6                   uci_magic_gamma_continuous   \n",
              "7                     uci_mushroom_categorical   \n",
              "8          uci_rice_cammeo_osmancik_continuous   \n",
              "9                      uci_spambase_continuous   \n",
              "10                         uci_wdbc_continuous   \n",
              "\n",
              "                                source  replicates  \\\n",
              "0                          uci:abalone          10   \n",
              "1                            uci:adult          10   \n",
              "2          uci:banknote-authentication          10   \n",
              "3                   uci:car-evaluation          10   \n",
              "4   uci:default-of-credit-card-clients          10   \n",
              "5               uci:letter-recognition          10   \n",
              "6            uci:magic-gamma-telescope          10   \n",
              "7                         uci:mushroom          10   \n",
              "8         uci:rice-cammeo-and-osmancik          10   \n",
              "9                         uci:spambase          10   \n",
              "10                            uci:wdbc          10   \n",
              "\n",
              "    true_positive_only_sample_size  true_unlabeled_to_labeled_positive_ratio  \\\n",
              "0                            900.0                                  2.000000   \n",
              "1                            900.0                                  2.000000   \n",
              "2                            701.2                                  2.001970   \n",
              "3                            440.4                                  1.986667   \n",
              "4                            900.0                                  2.000000   \n",
              "5                            759.1                                  2.002857   \n",
              "6                            900.0                                  2.000000   \n",
              "7                            900.0                                  2.000000   \n",
              "8                            900.0                                  2.000000   \n",
              "9                            900.0                                  2.000000   \n",
              "10                           313.5                                  1.995775   \n",
              "\n",
              "    true_outlier_rate  \n",
              "0            0.130435  \n",
              "1            0.130435  \n",
              "2            0.130219  \n",
              "3            0.128645  \n",
              "4            0.130435  \n",
              "5            0.129608  \n",
              "6            0.130435  \n",
              "7            0.130435  \n",
              "8            0.130435  \n",
              "9            0.130435  \n",
              "10           0.130860  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"True PU composition over replicates (additional table):\")\n",
        "composition_summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ffc25b30",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved evaluation outputs to: /Users/qltian/Library/CloudStorage/GoogleDrive-qltian2021@gmail.com/Other computers/My Laptop/Documents/Research/ai/slim_pretrain/pretrain_v2/evaluation_outputs/eval_20260228_023531\n",
            "- summary_metrics.csv\n",
            "- summary_metrics_latest.csv\n",
            "- summary_metrics_legacy.csv\n",
            "- metrics_by_model.csv\n",
            "- replicate_metrics.csv\n",
            "- dataset_feature_profile.csv\n",
            "- pu_composition_summary.csv\n"
          ]
        }
      ],
      "source": [
        "run_id = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = OUTPUT_DIR / f\"eval_{run_id}\"\n",
        "run_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "summary_path = run_dir / \"summary_metrics.csv\"\n",
        "summary_latest_path = run_dir / \"summary_metrics_latest.csv\"\n",
        "summary_legacy_path = run_dir / \"summary_metrics_legacy.csv\"\n",
        "metrics_by_model_path = run_dir / \"metrics_by_model.csv\"\n",
        "replicate_path = run_dir / \"replicate_metrics.csv\"\n",
        "profile_path = run_dir / \"dataset_feature_profile.csv\"\n",
        "composition_path = run_dir / \"pu_composition_summary.csv\"\n",
        "config_path = run_dir / \"run_config.json\"\n",
        "\n",
        "metrics_summary_df.to_csv(summary_path, index=False)\n",
        "metrics_latest_df.to_csv(summary_latest_path, index=False)\n",
        "metrics_legacy_df.to_csv(summary_legacy_path, index=False)\n",
        "metrics_by_model_df.to_csv(metrics_by_model_path, index=False)\n",
        "replicate_results_df.to_csv(replicate_path, index=False)\n",
        "profile_df.to_csv(profile_path, index=False)\n",
        "composition_summary_df.to_csv(composition_path, index=False)\n",
        "\n",
        "for dataset in prepared_datasets:\n",
        "    safe_name = \"\".join(ch if ch.isalnum() or ch in {\"_\", \"-\"} else \"_\" for ch in dataset[\"name\"])\n",
        "    dataset[\"feature_metadata\"].to_csv(run_dir / f\"feature_metadata_{safe_name}.csv\", index=False)\n",
        "\n",
        "run_config = {\n",
        "    \"checkpoint_path\": str(CHECKPOINT_PATH),\n",
        "    \"legacy_checkpoint_path\": str(LEGACY_CHECKPOINT_PATH),\n",
        "    \"legacy_model_commit\": LEGACY_MODEL_COMMIT,\n",
        "    \"device\": DEVICE,\n",
        "    \"allow_uci_download\": ALLOW_UCI_DOWNLOAD,\n",
        "    \"n_replicates\": N_REPLICATES,\n",
        "    \"max_attempts_per_dataset\": MAX_ATTEMPTS_PER_DATASET,\n",
        "    \"max_positive_size\": MAX_POSITIVE_SIZE,\n",
        "    \"unlabeled_labeled_positive_ratio\": list(UNLABELED_LABELED_POSITIVE_RATIO),\n",
        "    \"outlier_rate\": OUTLIER_RATE,\n",
        "    \"max_categorical_classes\": MAX_CATEGORICAL_CLASSES,\n",
        "    \"global_seed\": GLOBAL_SEED,\n",
        "}\n",
        "with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(run_config, f, indent=2)\n",
        "\n",
        "print(f\"Saved evaluation outputs to: {run_dir}\")\n",
        "print(f\"- {summary_path.name}\")\n",
        "print(f\"- {summary_latest_path.name}\")\n",
        "print(f\"- {summary_legacy_path.name}\")\n",
        "print(f\"- {metrics_by_model_path.name}\")\n",
        "print(f\"- {replicate_path.name}\")\n",
        "print(f\"- {profile_path.name}\")\n",
        "print(f\"- {composition_path.name}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "icl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
